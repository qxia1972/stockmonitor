"""
RQDatacæ•°æ®åŠ è½½å™¨ (RQDatac Data Loader)

ä¸“é—¨ç”¨äºä»RQDatacè·å–å„ç§æ•°æ®çš„åŠ è½½å™¨æ¨¡å—ï¼š
- è‚¡ç¥¨åˆ—è¡¨è·å–
- äº¤æ˜“æ—¥å†è·å–
- OHLCVæ•°æ®è·å–
- åŸºæœ¬é¢æ•°æ®è·å–
- æ•°æ®è§„èŒƒåŒæ­¥æ›´æ–°

ä½œè€…: ç³»ç»Ÿæ¶æ„å¸ˆ
åˆ›å»ºæ—¥æœŸ: 2025å¹´9æœˆ16æ—¥
"""

import logging
from typing import Dict, Any, Optional, Union, List, Tuple
from datetime import datetime, timedelta
from pathlib import Path
import json
import polars as pl

from modules.data_schema import (
    PRICE_FIELDS, FUNDAMENTAL_FIELDS, TECHNICAL_FIELDS,
    ALL_FIELDS, get_required_fields, get_optional_fields,
    FieldDefinition, DATA_FETCH_CONFIG
)

logger = logging.getLogger(__name__)


class RQDatacDataLoader:
    """RQDatacæ•°æ®åŠ è½½å™¨"""

    def __init__(self, allow_mock_data: bool = False):
        """
        åˆå§‹åŒ–RQDatacæ•°æ®åŠ è½½å™¨

        Args:
            allow_mock_data: æ˜¯å¦å…è®¸åœ¨RQDatacä¸å¯ç”¨æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
        """
        self._allow_mock_data = allow_mock_data
        self._rqdatac = None
        self._is_initialized = False
        self._instruments_cache: Optional[pl.DataFrame] = None
        self._trading_calendar_cache: Optional[List[str]] = None
        self._cache_expiry: Dict[str, datetime] = {}

        # å…ƒæ•°æ®ç®¡ç†
        self._metadata: Dict[str, Any] = {
            "data_source": "RQDatac",
            "version": "2.0.0",
            "last_fetch_time": None,
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "data_quality_metrics": {},
            "performance_stats": {}
        }

        # åˆå§‹åŒ–RQDatacè¿æ¥
        self._init_rqdatac()

    def _record_request_metadata(self, operation: str, success: bool,
                               record_count: int = 0, duration: float = 0.0):
        """è®°å½•è¯·æ±‚å…ƒæ•°æ®"""
        self._metadata["total_requests"] += 1
        self._metadata["last_fetch_time"] = datetime.now()

        if success:
            self._metadata["successful_requests"] += 1
        else:
            self._metadata["failed_requests"] += 1

        # è®°å½•æ€§èƒ½ç»Ÿè®¡
        if operation not in self._metadata["performance_stats"]:
            self._metadata["performance_stats"][operation] = {
                "count": 0,
                "total_duration": 0.0,
                "avg_duration": 0.0,
                "max_duration": 0.0,
                "min_duration": float('inf')
            }

        stats = self._metadata["performance_stats"][operation]
        stats["count"] += 1
        stats["total_duration"] += duration
        stats["avg_duration"] = stats["total_duration"] / stats["count"]
        stats["max_duration"] = max(stats["max_duration"], duration)
        stats["min_duration"] = min(stats["min_duration"], duration)

        # è®°å½•æ•°æ®è´¨é‡æŒ‡æ ‡
        if record_count > 0:
            if operation not in self._metadata["data_quality_metrics"]:
                self._metadata["data_quality_metrics"][operation] = {
                    "total_records": 0,
                    "avg_records_per_request": 0.0
                }

            quality = self._metadata["data_quality_metrics"][operation]
            quality["total_records"] += record_count
            quality["avg_records_per_request"] = quality["total_records"] / stats["count"]

    def get_metadata(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åŠ è½½å™¨å…ƒæ•°æ®"""
        return self._metadata.copy()

    def reset_metadata(self):
        """é‡ç½®å…ƒæ•°æ®ç»Ÿè®¡"""
        self._metadata.update({
            "last_fetch_time": None,
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "data_quality_metrics": {},
            "performance_stats": {}
        })
        logger.info("ğŸ”„ RQDatacæ•°æ®åŠ è½½å™¨å…ƒæ•°æ®å·²é‡ç½®")

    def _init_rqdatac(self):
        """åˆå§‹åŒ–RQDatacè¿æ¥"""
        try:
            import rqdatac
            rqdatac.init()
            self._rqdatac = rqdatac
            self._is_initialized = True
            logger.info("âœ… RQDatacåˆå§‹åŒ–æˆåŠŸ")
        except ImportError as e:
            if not self._allow_mock_data:
                logger.error(f"âŒ RQDatacæœªå®‰è£…: {e}")
                raise ConnectionError("RQDatacä¸å¯ç”¨ï¼Œæ— æ³•è·å–æ•°æ®") from e
            else:
                logger.warning("âš ï¸ RQDatacæœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                self._rqdatac = None
                self._is_initialized = False
        except Exception as e:
            if not self._allow_mock_data:
                logger.error(f"âŒ RQDatacåˆå§‹åŒ–å¤±è´¥: {e}")
                raise ConnectionError("RQDatacåˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•è·å–æ•°æ®") from e
            else:
                logger.error(f"âŒ RQDatacåˆå§‹åŒ–å¤±è´¥: {e}")
                self._rqdatac = None
                self._is_initialized = False

    def get_instruments(self,
                       instrument_type: str = "CS",
                       market: str = "cn",
                       refresh_cache: bool = False) -> pl.DataFrame:
        """
        è·å–è‚¡ç¥¨åˆ—è¡¨

        Args:
            instrument_type: è¯åˆ¸ç±»å‹ (CS=è‚¡ç¥¨, ETF=ETF, etc.)
            market: å¸‚åœº (cn=ä¸­å›½, hk=é¦™æ¸¯, us=ç¾å›½)
            refresh_cache: æ˜¯å¦åˆ·æ–°ç¼“å­˜

        Returns:
            è‚¡ç¥¨åˆ—è¡¨DataFrame
        """
        try:
            cache_key = f"instruments_{instrument_type}_{market}"

            # æ£€æŸ¥ç¼“å­˜
            if not refresh_cache and self._is_cache_valid(cache_key) and self._instruments_cache is not None:
                logger.info("ğŸ“‹ ä»ç¼“å­˜è·å–è‚¡ç¥¨åˆ—è¡¨")
                return self._instruments_cache

            if not self._is_initialized:
                if not self._allow_mock_data:
                    # RQDatacä¸å¯ç”¨ï¼Œç›´æ¥å¤±è´¥
                    raise ConnectionError("RQDatacä¸å¯ç”¨ï¼Œæ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨æ•°æ®")
                else:
                    # è¿”å›æ¨¡æ‹Ÿæ•°æ®
                    instruments_data = self._get_mock_instruments(instrument_type, market)
            else:
                # ä»RQDatacè·å–çœŸå®æ•°æ®
                instruments_data = self._fetch_instruments_from_rqdatac(instrument_type, market)

            # è½¬æ¢ä¸ºPolars DataFrame
            df = pl.DataFrame(instruments_data)

            # æ·»åŠ å…ƒæ•°æ®åˆ—
            df = df.with_columns([
                pl.lit("RQDatac").alias("_data_source"),
                pl.lit(datetime.now()).alias("_fetch_timestamp"),
                pl.lit(instrument_type).alias("_instrument_type"),
                pl.lit(market).alias("_market"),
                pl.lit(len(df)).alias("_total_instruments")
            ])

            # ç¼“å­˜ç»“æœ
            self._instruments_cache = df
            self._cache_expiry[cache_key] = datetime.now() + timedelta(hours=24)

            # è®°å½•å…ƒæ•°æ®
            self._record_request_metadata("get_instruments", True, len(df))

            logger.info(f"ğŸ“Š è·å–åˆ° {len(df)} åªè¯åˆ¸")
            return df

        except Exception as e:
            # è®°å½•å¤±è´¥çš„å…ƒæ•°æ®
            self._record_request_metadata("get_instruments", False)
            logger.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return pl.DataFrame()

    def get_trading_calendar(self,
                           market: str = "cn",
                           start_date: Optional[str] = None,
                           end_date: Optional[str] = None,
                           refresh_cache: bool = False) -> List[str]:
        """
        è·å–äº¤æ˜“æ—¥å†

        Args:
            market: å¸‚åœº
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            refresh_cache: æ˜¯å¦åˆ·æ–°ç¼“å­˜

        Returns:
            äº¤æ˜“æ—¥æœŸåˆ—è¡¨
        """
        try:
            cache_key = f"trading_calendar_{market}"

            # æ£€æŸ¥ç¼“å­˜
            if not refresh_cache and self._is_cache_valid(cache_key) and self._trading_calendar_cache is not None:
                logger.info("ğŸ“‹ ä»ç¼“å­˜è·å–äº¤æ˜“æ—¥å†")
                return self._trading_calendar_cache

            if not self._is_initialized:
                if not self._allow_mock_data:
                    # RQDatacä¸å¯ç”¨ï¼Œç›´æ¥å¤±è´¥
                    raise ConnectionError("RQDatacä¸å¯ç”¨ï¼Œæ— æ³•è·å–äº¤æ˜“æ—¥å†æ•°æ®")
                else:
                    # è¿”å›æ¨¡æ‹Ÿäº¤æ˜“æ—¥å†
                    trading_dates = self._get_mock_trading_calendar(start_date, end_date)
            else:
                # ä»RQDatacè·å–çœŸå®äº¤æ˜“æ—¥å†
                trading_dates = self._fetch_trading_calendar_from_rqdatac(market, start_date, end_date)

            # ç¼“å­˜ç»“æœ
            self._trading_calendar_cache = trading_dates
            self._cache_expiry[cache_key] = datetime.now() + timedelta(hours=24)

            logger.info(f"ğŸ“… è·å–åˆ° {len(trading_dates)} ä¸ªäº¤æ˜“æ—¥")
            return trading_dates

        except Exception as e:
            logger.error(f"âŒ è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
            return []

    def get_ohlcv_data(self,
                      symbols: List[str],
                      start_date: str,
                      end_date: str,
                      frequency: str = "1d",
                      adjust_type: str = "post") -> pl.DataFrame:
        """
        è·å–OHLCVæ•°æ®

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            frequency: é¢‘ç‡ (1d, 1m, etc.)
            adjust_type: å¤æƒç±»å‹ (post, pre, none)

        Returns:
            OHLCVæ•°æ®DataFrame
        """
        try:
            logger.info(f"ğŸ“ˆ è·å–OHLCVæ•°æ®: {len(symbols)} åªè‚¡ç¥¨, {start_date} åˆ° {end_date}")

            if not self._is_initialized:
                if not self._allow_mock_data:
                    # RQDatacä¸å¯ç”¨ï¼Œç›´æ¥å¤±è´¥
                    raise ConnectionError("RQDatacä¸å¯ç”¨ï¼Œæ— æ³•è·å–OHLCVæ•°æ®")
                else:
                    # è¿”å›æ¨¡æ‹Ÿæ•°æ®
                    ohlcv_data = self._get_mock_ohlcv_data(symbols, start_date, end_date)
            else:
                # ä»RQDatacè·å–çœŸå®æ•°æ®
                ohlcv_data = self._fetch_ohlcv_from_rqdatac(
                    symbols, start_date, end_date, frequency, adjust_type
                )

            df = pl.DataFrame(ohlcv_data)

            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            df = self._ensure_ohlcv_data_types(df)

            # æ·»åŠ å…ƒæ•°æ®åˆ—
            df = df.with_columns([
                pl.lit("RQDatac").alias("_data_source"),
                pl.lit(datetime.now()).alias("_fetch_timestamp"),
                pl.lit(frequency).alias("_frequency"),
                pl.lit(adjust_type).alias("_adjust_type"),
                pl.lit(len(symbols)).alias("_symbol_count"),
                pl.lit(len(df)).alias("_total_records")
            ])

            # è®°å½•å…ƒæ•°æ®
            self._record_request_metadata("get_ohlcv_data", True, len(df))

            logger.info(f"ğŸ“Š è·å–åˆ° {len(df)} æ¡OHLCVè®°å½•")
            return df

        except Exception as e:
            # è®°å½•å¤±è´¥çš„å…ƒæ•°æ®
            self._record_request_metadata("get_ohlcv_data", False)
            logger.error(f"âŒ è·å–OHLCVæ•°æ®å¤±è´¥: {e}")
            return pl.DataFrame()

    def get_dual_adjustment_ohlcv_data(self,
                                       symbols: List[str],
                                       start_date: str,
                                       end_date: str,
                                       frequency: str = "1d") -> pl.DataFrame:
        """
        è·å–åŒå¤æƒOHLCVæ•°æ®ï¼ˆåŒæ—¶åŒ…å«åå¤æƒå’Œå‰å¤æƒä»·æ ¼ï¼‰

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            frequency: é¢‘ç‡ (1d, 1m, etc.)

        Returns:
            åŒ…å«ä¸¤ç§å¤æƒä»·æ ¼çš„OHLCVæ•°æ®DataFrame
        """
        try:
            logger.info(f"ï¿½ è·å–åŒå¤æƒOHLCVæ•°æ®: {len(symbols)} åªè‚¡ç¥¨, {start_date} åˆ° {end_date}")

            if not self._is_initialized:
                if not self._allow_mock_data:
                    raise ConnectionError("RQDatacä¸å¯ç”¨ï¼Œæ— æ³•è·å–OHLCVæ•°æ®")
                else:
                    # è¿”å›æ¨¡æ‹Ÿæ•°æ®ï¼ˆæš‚æ—¶ä½¿ç”¨é»˜è®¤å¤æƒï¼‰
                    ohlcv_data = self._get_mock_ohlcv_data(symbols, start_date, end_date)
                    df = pl.DataFrame(ohlcv_data)
            else:
                # è·å–åå¤æƒæ•°æ®
                post_data = self._fetch_ohlcv_from_rqdatac(
                    symbols, start_date, end_date, frequency, "post"
                )

                # è·å–å‰å¤æƒæ•°æ®
                pre_data = self._fetch_ohlcv_from_rqdatac(
                    symbols, start_date, end_date, frequency, "pre"
                )

                # åˆå¹¶ä¸¤ç§å¤æƒæ•°æ®
                df = self._merge_dual_adjustment_data(post_data, pre_data)

            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            df = self._ensure_dual_ohlcv_data_types(df)

            # æ·»åŠ å…ƒæ•°æ®åˆ—
            df = df.with_columns([
                pl.lit("RQDatac").alias("_data_source"),
                pl.lit(datetime.now()).alias("_fetch_timestamp"),
                pl.lit(frequency).alias("_frequency"),
                pl.lit("dual").alias("_adjust_type"),  # æ ‡è®°ä¸ºåŒå¤æƒæ•°æ®
                pl.lit(len(symbols)).alias("_symbol_count"),
                pl.lit(len(df)).alias("_total_records")
            ])

            # è®°å½•å…ƒæ•°æ®
            self._record_request_metadata("get_dual_adjustment_ohlcv_data", True, len(df))

            logger.info(f"ï¿½ğŸ“Š è·å–åˆ° {len(df)} æ¡åŒå¤æƒOHLCVè®°å½•")
            return df

        except Exception as e:
            # è®°å½•å¤±è´¥çš„å…ƒæ•°æ®
            self._record_request_metadata("get_dual_adjustment_ohlcv_data", False)
            logger.error(f"âŒ è·å–åŒå¤æƒOHLCVæ•°æ®å¤±è´¥: {e}")
            return pl.DataFrame()

    def get_fundamental_data(self,
                           symbols: List[str],
                           fields: Optional[List[str]] = None,
                           start_date: Optional[str] = None,
                           end_date: Optional[str] = None) -> pl.DataFrame:
        """
        è·å–åŸºæœ¬é¢æ•°æ®

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            fields: å­—æ®µåˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è·å–æ‰€æœ‰åŸºæœ¬é¢å­—æ®µ
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            åŸºæœ¬é¢æ•°æ®DataFrame
        """
        try:
            if fields is None:
                fields = list(FUNDAMENTAL_FIELDS.keys())

            logger.info(f"ğŸ“Š è·å–åŸºæœ¬é¢æ•°æ®: {len(symbols)} åªè‚¡ç¥¨, {len(fields)} ä¸ªå­—æ®µ")

            if not self._is_initialized:
                if not self._allow_mock_data:
                    # RQDatacä¸å¯ç”¨ï¼Œç›´æ¥å¤±è´¥
                    raise ConnectionError("RQDatacä¸å¯ç”¨ï¼Œæ— æ³•è·å–åŸºæœ¬é¢æ•°æ®")
                else:
                    # è¿”å›æ¨¡æ‹Ÿæ•°æ®
                    fundamental_data = self._get_mock_fundamental_data(symbols, fields, start_date, end_date)
            else:
                # ä»RQDatacè·å–çœŸå®æ•°æ®
                fundamental_data = self._fetch_fundamental_from_rqdatac(
                    symbols, fields, start_date, end_date
                )

            df = pl.DataFrame(fundamental_data)

            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            df = self._ensure_fundamental_data_types(df)

            logger.info(f"ğŸ“Š è·å–åˆ° {len(df)} æ¡åŸºæœ¬é¢è®°å½•")
            return df

        except Exception as e:
            logger.error(f"âŒ è·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
            return pl.DataFrame()

    def get_factor_data(self,
                        symbols: List[str],
                        factors: Optional[List[str]] = None,
                        start_date: Optional[str] = None,
                        end_date: Optional[str] = None) -> pl.DataFrame:
        """
        ä»RQDatacå› å­åº“è·å–å› å­æ•°æ®

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            factors: å› å­åç§°åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™è·å–æ‰€æœ‰å¯ç”¨å› å­
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            å› å­æ•°æ®DataFrame
        """
        try:
            if factors is None:
                # è·å–æ‰€æœ‰åŸºæœ¬é¢ç›¸å…³çš„å› å­
                factors = [
                    'pe_ratio', 'pb_ratio', 'ps_ratio', 'pcf_ratio', 'market_cap',
                    'circulating_market_cap', 'turnover_ratio', 'float_turnover_ratio',
                    'roe', 'roa', 'gross_profit_margin', 'net_profit_margin',
                    'current_ratio', 'debt_to_equity', 'total_assets', 'total_liabilities'
                ]

            logger.info(f"ï¿½ ä»å› å­åº“è·å–æ•°æ®: {len(symbols)} åªè‚¡ç¥¨, {len(factors)} ä¸ªå› å­")

            if not self._is_initialized:
                if not self._allow_mock_data:
                    # RQDatacä¸å¯ç”¨ï¼Œç›´æ¥å¤±è´¥
                    raise ConnectionError("RQDatacä¸å¯ç”¨ï¼Œæ— æ³•è·å–å› å­æ•°æ®")
                else:
                    # è¿”å›æ¨¡æ‹Ÿæ•°æ®
                    factor_data = self._get_mock_factor_data(symbols, factors, start_date, end_date)
            else:
                # ä»RQDatacå› å­åº“è·å–çœŸå®æ•°æ®
                factor_data = self._fetch_factors_from_rqdatac(
                    symbols, factors, start_date, end_date
                )

            df = pl.DataFrame(factor_data)

            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            df = self._ensure_factor_data_types(df)

            # æ·»åŠ å…ƒæ•°æ®åˆ—
            df = df.with_columns([
                pl.lit("RQDatac").alias("_data_source"),
                pl.lit(datetime.now()).alias("_fetch_timestamp"),
                pl.lit("factor").alias("_data_type"),
                pl.lit(len(symbols)).alias("_symbol_count"),
                pl.lit(len(factors)).alias("_factor_count"),
                pl.lit(len(df)).alias("_total_records")
            ])

            # è®°å½•å…ƒæ•°æ®
            self._record_request_metadata("get_factor_data", True, len(df))

            logger.info(f"ğŸ“Š ä»å› å­åº“è·å–åˆ° {len(df)} æ¡è®°å½•")
            return df

        except Exception as e:
            # è®°å½•å¤±è´¥çš„å…ƒæ•°æ®
            self._record_request_metadata("get_factor_data", False)
            logger.error(f"âŒ ä»å› å­åº“è·å–æ•°æ®å¤±è´¥: {e}")
            return pl.DataFrame()

    def update_data_schema_from_rqdatac(self):
        """
        æ ¹æ®RQDatacçš„å®é™…æ•°æ®ç»“æ„æ›´æ–°æ•°æ®è§„èŒƒ

        è¿™ä¸ªæ–¹æ³•ä¼šï¼š
        1. è·å–RQDatacçš„å®é™…å­—æ®µä¿¡æ¯
        2. æ›´æ–°data_field_definitions.pyä¸­çš„å­—æ®µå®šä¹‰
        3. æ›´æ–°config/schemas/ä¸­çš„schemaæ–‡ä»¶
        """
        try:
            logger.info("ğŸ”„ å¼€å§‹æ›´æ–°æ•°æ®è§„èŒƒ...")

            if not self._is_initialized:
                logger.warning("âš ï¸ RQDatacæœªåˆå§‹åŒ–ï¼Œè·³è¿‡æ•°æ®è§„èŒƒæ›´æ–°")
                return

            # è·å–å®é™…çš„å­—æ®µä¿¡æ¯
            actual_fields = self._get_actual_fields_from_rqdatac()

            # æ›´æ–°å­—æ®µå®šä¹‰
            self._update_field_definitions(actual_fields)

            # æ›´æ–°schemaæ–‡ä»¶
            self._update_schema_files(actual_fields)

            logger.info("âœ… æ•°æ®è§„èŒƒæ›´æ–°å®Œæˆ")

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ•°æ®è§„èŒƒå¤±è´¥: {e}")

    # ===== ç§æœ‰æ–¹æ³• =====

    def _is_cache_valid(self, cache_key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if cache_key not in self._cache_expiry:
            return False
        return datetime.now() < self._cache_expiry[cache_key]

    def _fetch_instruments_from_rqdatac(self, instrument_type: str, market: str) -> List[Dict]:
        """ä»RQDatacè·å–è‚¡ç¥¨åˆ—è¡¨"""
        try:
            if self._rqdatac is None:
                raise ValueError("RQDatacæœªåˆå§‹åŒ–")

            # RQDatacè·å–è¯åˆ¸åˆ—è¡¨ - ä½¿ç”¨æ­£ç¡®çš„API
            try:
                # å°è¯•è·å–å…¨éƒ¨Aè‚¡è‚¡ç¥¨
                instruments = self._rqdatac.all_instruments(type=instrument_type, market=market)  # type: ignore
            except AttributeError:
                try:
                    # å¦‚æœæ²¡æœ‰all_instrumentsæ–¹æ³•ï¼Œå°è¯•ä½¿ç”¨instrumentsä½†ä¸ä¼ å‚æ•°
                    instruments = self._rqdatac.instruments(type=instrument_type, market=market)  # type: ignore
                except (AttributeError, TypeError):
                    # å¦‚æœéƒ½æ²¡æœ‰ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                    logger.warning("RQDatac APIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨è‚¡ç¥¨åˆ—è¡¨")
                    return self._get_fallback_instruments(instrument_type, market)

            # å¤„ç†RQDatacè¿”å›çš„æ•°æ®æ ¼å¼
            instruments_data = []
            if hasattr(instruments, 'iterrows'):  # DataFrameæ ¼å¼
                for idx, row in instruments.iterrows():
                    instruments_data.append({
                        "order_book_id": str(row.get('order_book_id', row.get('code', idx))),
                        "symbol": str(row.get('symbol', row.get('name', idx))),
                        "exchange": str(row.get('exchange', market.upper())),
                        "type": str(row.get('type', instrument_type)),
                        "status": str(row.get('status', 'Active')),
                        "listed_date": str(row.get('listed_date', '1990-01-01')),
                        "de_listed_date": str(row.get('de_listed_date', '')),
                        "sector_code": str(row.get('sector_code', '')),
                        "industry_code": str(row.get('industry_code', '')),
                        "board_type": str(row.get('board_type', '')),
                        "data_date": datetime.now().strftime("%Y-%m-%d"),
                        "updated_at": datetime.now().isoformat()
                    })
            elif hasattr(instruments, '__iter__'):  # åˆ—è¡¨æˆ–ç±»ä¼¼å¯è¿­ä»£å¯¹è±¡
                for inst in instruments:
                    if hasattr(inst, '__dict__'):  # å¯¹è±¡æ ¼å¼
                        instruments_data.append({
                            "order_book_id": getattr(inst, 'order_book_id', getattr(inst, 'code', str(inst))),
                            "symbol": getattr(inst, 'symbol', getattr(inst, 'name', str(inst))),
                            "exchange": getattr(inst, 'exchange', market.upper()),
                            "type": getattr(inst, 'type', instrument_type),
                            "status": getattr(inst, 'status', 'Active'),
                            "listed_date": getattr(inst, 'listed_date', '1990-01-01'),
                            "de_listed_date": getattr(inst, 'de_listed_date', ''),
                            "sector_code": getattr(inst, 'sector_code', ''),
                            "industry_code": getattr(inst, 'industry_code', ''),
                            "board_type": getattr(inst, 'board_type', ''),
                            "data_date": datetime.now().strftime("%Y-%m-%d"),
                            "updated_at": datetime.now().isoformat()
                        })
                    else:  # å­—å…¸æ ¼å¼
                        instruments_data.append({
                            "order_book_id": str(inst.get('order_book_id', inst.get('code', inst))),
                            "symbol": str(inst.get('symbol', inst.get('name', inst))),
                            "exchange": str(inst.get('exchange', market.upper())),
                            "type": str(inst.get('type', instrument_type)),
                            "status": str(inst.get('status', 'Active')),
                            "listed_date": str(inst.get('listed_date', '1990-01-01')),
                            "de_listed_date": str(inst.get('de_listed_date', '')),
                            "sector_code": str(inst.get('sector_code', '')),
                            "industry_code": str(inst.get('industry_code', '')),
                            "board_type": str(inst.get('board_type', '')),
                            "data_date": datetime.now().strftime("%Y-%m-%d"),
                            "updated_at": datetime.now().isoformat()
                        })
            else:
                logger.warning(f"æœªçŸ¥çš„æ•°æ®æ ¼å¼: {type(instruments)}")
                return self._get_fallback_instruments(instrument_type, market)

            logger.info(f"æˆåŠŸè·å– {len(instruments_data)} åªè‚¡ç¥¨")
            return instruments_data

        except Exception as e:
            logger.error(f"è·å–RQDatacè‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return self._get_fallback_instruments(instrument_type, market)

    def _fetch_trading_calendar_from_rqdatac(self, market: str,
                                           start_date: Optional[str],
                                           end_date: Optional[str]) -> List[str]:
        """ä»RQDatacè·å–äº¤æ˜“æ—¥å†"""
        try:
            if self._rqdatac is None:
                raise ValueError("RQDatacæœªåˆå§‹åŒ–")

            # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´
            if start_date is None:
                start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
            if end_date is None:
                end_date = datetime.now().strftime("%Y-%m-%d")

            # RQDatacè·å–äº¤æ˜“æ—¥å†
            trading_dates = self._rqdatac.get_trading_dates(start_date, end_date)  # type: ignore

            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
            return [date.strftime("%Y-%m-%d") for date in trading_dates]

        except Exception as e:
            logger.error(f"ä»RQDatacè·å–äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
            return []

    def _fetch_ohlcv_from_rqdatac(self, symbols: List[str], start_date: str,
                                end_date: str, frequency: str, adjust_type: str) -> List[Dict]:
        """ä»RQDatacè·å–OHLCVæ•°æ®"""
        try:
            if self._rqdatac is None:
                raise ValueError("RQDatacæœªåˆå§‹åŒ–")

            # RQDatacè·å–ä»·æ ¼æ•°æ® - ä½¿ç”¨æ­£ç¡®çš„å‚æ•°å
            price_data = self._rqdatac.get_price(  # type: ignore
                order_book_ids=symbols,  # æ³¨æ„ï¼šä½¿ç”¨order_book_idsè€Œä¸æ˜¯symbols
                start_date=start_date,
                end_date=end_date,
                frequency=frequency,
                adjust_type=adjust_type
            )

            # RQDatacè¿”å›çš„æ˜¯MultiIndex DataFrameï¼Œéœ€è¦æ­£ç¡®å¤„ç†
            ohlcv_data = []

            # é‡ç½®ç´¢å¼•ä»¥è·å–order_book_idå’Œdateä½œä¸ºåˆ—
            if hasattr(price_data.index, 'names') and price_data.index.names == ['order_book_id', 'date']:
                # MultiIndexçš„æƒ…å†µ
                price_data = price_data.reset_index()

            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            for record in price_data.to_dict('records'):
                ohlcv_data.append({
                    "order_book_id": record.get("order_book_id"),
                    "date": record.get("date").strftime("%Y-%m-%d") if hasattr(record.get("date"), 'strftime') else str(record.get("date")),
                    "open": record.get("open"),
                    "close": record.get("close"),
                    "high": record.get("high"),
                    "low": record.get("low"),
                    "volume": record.get("volume"),
                    "amount": record.get("total_turnover"),  # RQDatacä½¿ç”¨total_turnoverè€Œä¸æ˜¯amount
                    "vwap": record.get("vwap"),
                    "returns": record.get("returns"),
                    "volume_ratio": record.get("volume_ratio")
                })

            return ohlcv_data

        except Exception as e:
            logger.error(f"ä»RQDatacè·å–OHLCVæ•°æ®å¤±è´¥: {e}")
            return []

    def _merge_dual_adjustment_data(self, post_data: List[Dict], pre_data: List[Dict]) -> pl.DataFrame:
        """åˆå¹¶åå¤æƒå’Œå‰å¤æƒæ•°æ®"""
        try:
            # è½¬æ¢ä¸ºDataFrame
            post_df = pl.DataFrame(post_data)
            pre_df = pl.DataFrame(pre_data)

            # é‡å‘½åå‰å¤æƒåˆ—ä»¥åŒºåˆ†
            pre_df = pre_df.rename({
                "open": "open_pre",
                "close": "close_pre",
                "high": "high_pre",
                "low": "low_pre",
                "vwap": "vwap_pre"
            })

            # åˆå¹¶æ•°æ®ï¼ˆåŸºäºorder_book_idå’Œdateï¼‰
            merged_df = post_df.join(
                pre_df.select(["order_book_id", "date", "open_pre", "close_pre", "high_pre", "low_pre", "vwap_pre"]),
                on=["order_book_id", "date"],
                how="left"
            )

            return merged_df

        except Exception as e:
            logger.error(f"åˆå¹¶åŒå¤æƒæ•°æ®å¤±è´¥: {e}")
            # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œè¿”å›åå¤æƒæ•°æ®
            return pl.DataFrame(post_data)

    def _ensure_dual_ohlcv_data_types(self, df: pl.DataFrame) -> pl.DataFrame:
        """ç¡®ä¿åŒå¤æƒOHLCVæ•°æ®ç±»å‹æ­£ç¡®"""
        try:
            # åŸºç¡€å­—æ®µç±»å‹
            df = df.with_columns([
                pl.col('date').cast(pl.Date).alias('date'),
                pl.col('order_book_id').cast(pl.Utf8).alias('order_book_id'),
                pl.col('open').cast(pl.Float64).alias('open'),
                pl.col('high').cast(pl.Float64).alias('high'),
                pl.col('low').cast(pl.Float64).alias('low'),
                pl.col('close').cast(pl.Float64).alias('close'),
                pl.col('volume').cast(pl.Int64).alias('volume'),
                pl.col('amount').cast(pl.Float64).alias('amount'),
                pl.col('vwap').cast(pl.Float64).alias('vwap'),
                pl.col('returns').cast(pl.Float64).alias('returns'),
                pl.col('volume_ratio').cast(pl.Float64).alias('volume_ratio')
            ])

            # å‰å¤æƒå­—æ®µç±»å‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if 'open_pre' in df.columns:
                df = df.with_columns([
                    pl.col('open_pre').cast(pl.Float64).alias('open_pre'),
                    pl.col('high_pre').cast(pl.Float64).alias('high_pre'),
                    pl.col('low_pre').cast(pl.Float64).alias('low_pre'),
                    pl.col('close_pre').cast(pl.Float64).alias('close_pre'),
                    pl.col('vwap_pre').cast(pl.Float64).alias('vwap_pre')
                ])

            return df

        except Exception as e:
            logger.error(f"ç¡®ä¿åŒå¤æƒæ•°æ®ç±»å‹å¤±è´¥: {e}")
            return df

    def _fetch_fundamental_from_rqdatac(self, symbols: List[str], fields: List[str],
                                      start_date: Optional[str], end_date: Optional[str]) -> List[Dict]:
        """ä»RQDatacè·å–åŸºæœ¬é¢æ•°æ®"""
        try:
            if self._rqdatac is None:
                raise ValueError("RQDatacæœªåˆå§‹åŒ–")

            fundamental_data = []

            # åˆ†æ‰¹è·å–æ¯ä¸ªå­—æ®µçš„æ•°æ®
            for field in fields:
                try:
                    field_data = self._rqdatac.get_factor(  # type: ignore
                        order_book_ids=symbols,  # æ³¨æ„ï¼šä½¿ç”¨order_book_idsè€Œä¸æ˜¯symbols
                        factor=field,
                        start_date=start_date,
                        end_date=end_date
                    )

                    # åˆå¹¶åˆ°ç»“æœä¸­
                    for record in field_data.to_dict('records'):
                        # æŸ¥æ‰¾æˆ–åˆ›å»ºè®°å½•
                        existing_record = None
                        for item in fundamental_data:
                            if (item.get("order_book_id") == record.get("order_book_id") and
                                item.get("date") == record.get("date")):
                                existing_record = item
                                break

                        if existing_record is None:
                            existing_record = {
                                "order_book_id": record.get("order_book_id"),
                                "date": record.get("date").strftime("%Y-%m-%d") if record.get("date") else None,
                            }
                            fundamental_data.append(existing_record)

                        # æ·»åŠ å­—æ®µå€¼
                        existing_record[field] = record.get("factor_value")

                except Exception as e:
                    logger.warning(f"è·å–å­—æ®µ {field} æ•°æ®å¤±è´¥: {e}")
                    continue

            return fundamental_data

        except Exception as e:
            logger.error(f"ä»RQDatacè·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
            return []

    def _fetch_technical_from_rqdatac(self, symbols: List[str], indicators: List[str],
                                    start_date: Optional[str], end_date: Optional[str]) -> List[Dict]:
        """ä»RQDatacè·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®"""
        try:
            if self._rqdatac is None:
                raise ValueError("RQDatacæœªåˆå§‹åŒ–")

            technical_data = []

            # åˆ†æ‰¹è·å–æ¯ä¸ªæŒ‡æ ‡çš„æ•°æ®
            for indicator in indicators:
                try:
                    # RQDatacå¯èƒ½æ²¡æœ‰ç›´æ¥çš„æŠ€æœ¯æŒ‡æ ‡APIï¼Œéœ€è¦ä½¿ç”¨å…¶ä»–æ–¹å¼
                    # è¿™é‡Œå…ˆä½¿ç”¨get_factoræ¥è·å–ä¸€äº›æŠ€æœ¯æŒ‡æ ‡æ•°æ®
                    if indicator in ["sma_20", "sma_50", "ema_20", "ema_50"]:
                        # å¯¹äºç§»åŠ¨å¹³å‡çº¿ï¼Œä½¿ç”¨ä»·æ ¼æ•°æ®è®¡ç®—
                        price_data = self._rqdatac.get_price(  # type: ignore
                            order_book_ids=symbols,
                            start_date=start_date,
                            end_date=end_date,
                            frequency="1d"
                        )
                        # è¿™é‡Œå¯ä»¥æ·»åŠ è®¡ç®—ç§»åŠ¨å¹³å‡çº¿çš„é€»è¾‘
                        # æš‚æ—¶è¿”å›ç©ºæ•°æ®
                        continue
                    else:
                        # å¯¹äºå…¶ä»–æŒ‡æ ‡ï¼Œå°è¯•ä½¿ç”¨get_factor
                        indicator_data = self._rqdatac.get_factor(  # type: ignore
                            order_book_ids=symbols,
                            factor=indicator,
                            start_date=start_date,
                            end_date=end_date
                        )

                    # åˆå¹¶åˆ°ç»“æœä¸­
                    for record in indicator_data.to_dict('records'):
                        # æŸ¥æ‰¾æˆ–åˆ›å»ºè®°å½•
                        existing_record = None
                        for item in technical_data:
                            if (item.get("order_book_id") == record.get("order_book_id") and
                                item.get("date") == record.get("date")):
                                existing_record = item
                                break

                        if existing_record is None:
                            existing_record = {
                                "order_book_id": record.get("order_book_id"),
                                "date": record.get("date").strftime("%Y-%m-%d") if record.get("date") else None,
                            }
                            technical_data.append(existing_record)

                        # æ·»åŠ æŒ‡æ ‡å€¼
                        existing_record[indicator] = record.get("factor_value")

                except Exception as e:
                    logger.warning(f"è·å–æŒ‡æ ‡ {indicator} æ•°æ®å¤±è´¥: {e}")
                    continue

            return technical_data

        except Exception as e:
            logger.error(f"ä»RQDatacè·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
            return []

    def _ensure_ohlcv_data_types(self, df: pl.DataFrame) -> pl.DataFrame:
        """ç¡®ä¿OHLCVæ•°æ®ç±»å‹æ­£ç¡®"""
        if df.is_empty():
            return df

        # å®šä¹‰ç±»å‹æ˜ å°„
        type_mapping = {
            "open": pl.Float64,
            "close": pl.Float64,
            "high": pl.Float64,
            "low": pl.Float64,
            "volume": pl.Int64,
            "amount": pl.Float64,
            "vwap": pl.Float64,
            "returns": pl.Float64,
            "volume_ratio": pl.Float64
        }

        for col, dtype in type_mapping.items():
            if col in df.columns:
                df = df.with_columns(pl.col(col).cast(dtype))

        return df

    def _ensure_fundamental_data_types(self, df: pl.DataFrame) -> pl.DataFrame:
        """ç¡®ä¿åŸºæœ¬é¢æ•°æ®ç±»å‹æ­£ç¡®"""
        if df.is_empty():
            return df

        # æ‰€æœ‰åŸºæœ¬é¢å­—æ®µéƒ½æ˜¯float64ç±»å‹
        for col in FUNDAMENTAL_FIELDS.keys():
            if col in df.columns:
                df = df.with_columns(pl.col(col).cast(pl.Float64))

        return df

    def _ensure_technical_data_types(self, df: pl.DataFrame) -> pl.DataFrame:
        """ç¡®ä¿æŠ€æœ¯æŒ‡æ ‡æ•°æ®ç±»å‹æ­£ç¡®"""
        if df.is_empty():
            return df

        # æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡å­—æ®µéƒ½æ˜¯float64ç±»å‹
        for col in TECHNICAL_FIELDS.keys():
            if col in df.columns:
                df = df.with_columns(pl.col(col).cast(pl.Float64))

        return df

    def _ensure_factor_data_types(self, df: pl.DataFrame) -> pl.DataFrame:
        """ç¡®ä¿å› å­æ•°æ®ç±»å‹æ­£ç¡®"""
        if df.is_empty():
            return df

        # å› å­æ•°æ®ä¸»è¦æ˜¯æ•°å€¼ç±»å‹
        factor_fields = [
            'pe_ratio', 'pb_ratio', 'ps_ratio', 'pcf_ratio', 'market_cap',
            'circulating_market_cap', 'turnover_ratio', 'float_turnover_ratio',
            'roe', 'roa', 'gross_profit_margin', 'net_profit_margin',
            'current_ratio', 'debt_to_equity', 'total_assets', 'total_liabilities'
        ]

        for col in factor_fields:
            if col in df.columns:
                df = df.with_columns(pl.col(col).cast(pl.Float64))

        return df

    def _get_mock_factor_data(self, symbols: List[str], factors: List[str],
                             start_date: Optional[str], end_date: Optional[str]) -> List[Dict]:
        """è·å–æ¨¡æ‹Ÿå› å­æ•°æ®"""
        import numpy as np
        from datetime import datetime, timedelta

        factor_data = []

        # ç”Ÿæˆæ—¥æœŸèŒƒå›´
        if start_date and end_date:
            start = datetime.strptime(start_date, "%Y-%m-%d")
            end = datetime.strptime(end_date, "%Y-%m-%d")
        else:
            end = datetime.now()
            start = end - timedelta(days=30)

        dates = []
        current = start
        while current <= end:
            if current.weekday() < 5:  # å‘¨ä¸€åˆ°å‘¨äº”
                dates.append(current.strftime("%Y-%m-%d"))
            current += timedelta(days=1)

        # ä¸ºæ¯ä¸ªè‚¡ç¥¨å’Œæ—¥æœŸç”Ÿæˆå› å­æ•°æ®
        for symbol in symbols:
            for date in dates:
                record = {
                    "order_book_id": symbol,
                    "date": date
                }

                # ç”Ÿæˆæ¨¡æ‹Ÿå› å­å€¼
                np.random.seed(hash(symbol + date) % 2**32)
                for factor in factors:
                    if 'ratio' in factor or 'margin' in factor:
                        record[factor] = round(np.random.uniform(0.1, 5.0), 2)
                    elif 'market_cap' in factor:
                        record[factor] = round(np.random.uniform(1e9, 1e12), 2)
                    elif 'turnover' in factor:
                        record[factor] = round(np.random.uniform(0.1, 10.0), 2)
                    else:
                        record[factor] = round(np.random.uniform(0.1, 100.0), 2)

                factor_data.append(record)

        return factor_data

    def _fetch_factors_from_rqdatac(self, symbols: List[str], factors: List[str],
                                   start_date: Optional[str], end_date: Optional[str]) -> List[Dict]:
        """ä»RQDatacå› å­åº“è·å–å› å­æ•°æ®"""
        try:
            if self._rqdatac is None:
                raise ValueError("RQDatacæœªåˆå§‹åŒ–")

            factor_data = []

            # åˆ†æ‰¹è·å–æ¯ä¸ªå› å­çš„æ•°æ®
            for factor in factors:
                try:
                    logger.info(f"ä»å› å­åº“è·å–å› å­: {factor}")

                    factor_result = self._rqdatac.get_factor(  # type: ignore
                        order_book_ids=symbols,
                        factor=factor,
                        start_date=start_date,
                        end_date=end_date
                    )

                    # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
                    if factor_result is None or factor_result.empty:
                        logger.warning(f"å› å­ {factor} è¿”å›ç©ºç»“æœ")
                        continue

                    # é‡ç½®ç´¢å¼•ä»¥è·å–order_book_idå’Œdateä½œä¸ºåˆ—
                    factor_result = factor_result.reset_index()

                    # åˆå¹¶åˆ°ç»“æœä¸­
                    for record in factor_result.to_dict('records'):
                        # æŸ¥æ‰¾æˆ–åˆ›å»ºè®°å½•
                        existing_record = None
                        for item in factor_data:
                            if (item.get("order_book_id") == record.get("order_book_id") and
                                item.get("date") == record.get("date")):
                                existing_record = item
                                break

                        if existing_record is None:
                            existing_record = {
                                "order_book_id": record.get("order_book_id"),
                                "date": record.get("date"),  # å·²ç»æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                            }
                            factor_data.append(existing_record)

                        # æ·»åŠ å› å­å€¼ - ä½¿ç”¨å› å­åä½œä¸ºé”®
                        existing_record[factor] = record.get(factor)

                except Exception as e:
                    logger.warning(f"è·å–å› å­ {factor} æ•°æ®å¤±è´¥: {e}")
                    # å¯¹äºè·å–å¤±è´¥çš„å› å­ï¼Œæ ‡è®°ä¸ºNoneï¼Œåç»­ç”±æŒ‡æ ‡è®¡ç®—æ¨¡å—å¤„ç†
                    continue

            return factor_data

        except Exception as e:
            logger.error(f"ä»RQDatacå› å­åº“è·å–æ•°æ®å¤±è´¥: {e}")
            return []

    def get_technical_data(self,
                          symbols: List[str],
                          indicators: Optional[List[str]] = None,
                          start_date: Optional[str] = None,
                          end_date: Optional[str] = None) -> pl.DataFrame:
        """
        è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®

        Args:
            symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            indicators: æŠ€æœ¯æŒ‡æ ‡åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            æŠ€æœ¯æŒ‡æ ‡æ•°æ®DataFrame
        """
        try:
            if indicators is None:
                indicators = list(TECHNICAL_FIELDS.keys())

            logger.info(f"ğŸ“ˆ è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®: {len(symbols)} åªè‚¡ç¥¨, {len(indicators)} ä¸ªæŒ‡æ ‡")

            if not self._is_initialized:
                if not self._allow_mock_data:
                    # RQDatacä¸å¯ç”¨ï¼Œç›´æ¥å¤±è´¥
                    raise ConnectionError("RQDatacä¸å¯ç”¨ï¼Œæ— æ³•è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®")
                else:
                    # è¿”å›æ¨¡æ‹Ÿæ•°æ®
                    technical_data = self._get_mock_technical_data(symbols, indicators, start_date, end_date)
            else:
                # ä»RQDatacè·å–çœŸå®æ•°æ®
                technical_data = self._fetch_technical_from_rqdatac(
                    symbols, indicators, start_date, end_date
                )

            df = pl.DataFrame(technical_data)

            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            df = self._ensure_technical_data_types(df)

            logger.info(f"ğŸ“Š è·å–åˆ° {len(df)} æ¡æŠ€æœ¯æŒ‡æ ‡è®°å½•")
            return df

        except Exception as e:
            logger.error(f"âŒ è·å–æŠ€æœ¯æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
            return pl.DataFrame()

    # ===== æ¨¡æ‹Ÿæ•°æ®æ–¹æ³•ï¼ˆç”¨äºæµ‹è¯•ï¼‰ =====

    def _get_mock_instruments(self, instrument_type: str, market: str) -> List[Dict]:
        """è·å–æ¨¡æ‹Ÿè‚¡ç¥¨åˆ—è¡¨æ•°æ®"""
        mock_instruments = [
            {
                "order_book_id": "000001.XSHE",
                "symbol": "å¹³å®‰é“¶è¡Œ",
                "exchange": "XSHE",
                "type": "CS",
                "status": "Active",
                "listed_date": "1991-04-03",
                "sector_code": "J66",
                "industry_code": "J661",
                "board_type": "ä¸»æ¿",
                "data_date": datetime.now().strftime("%Y-%m-%d"),
                "updated_at": datetime.now().isoformat()
            },
            {
                "order_book_id": "000002.XSHE",
                "symbol": "ä¸‡ç§‘A",
                "exchange": "XSHE",
                "type": "CS",
                "status": "Active",
                "listed_date": "1991-01-29",
                "sector_code": "K70",
                "industry_code": "K701",
                "board_type": "ä¸»æ¿",
                "data_date": datetime.now().strftime("%Y-%m-%d"),
                "updated_at": datetime.now().isoformat()
            }
        ]
        return mock_instruments

    def _get_mock_trading_calendar(self, start_date: Optional[str], end_date: Optional[str]) -> List[str]:
        """è·å–æ¨¡æ‹Ÿäº¤æ˜“æ—¥å†"""
        if start_date is None:
            start_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        # ç”Ÿæˆå·¥ä½œæ—¥åˆ—è¡¨ï¼ˆæ’é™¤å‘¨æœ«ï¼‰
        trading_dates = []
        current = datetime.strptime(start_date, "%Y-%m-%d")
        end = datetime.strptime(end_date, "%Y-%m-%d")

        while current <= end:
            if current.weekday() < 5:  # å‘¨ä¸€åˆ°å‘¨äº”
                trading_dates.append(current.strftime("%Y-%m-%d"))
            current += timedelta(days=1)

        return trading_dates

    def _get_mock_ohlcv_data(self, symbols: List[str], start_date: str, end_date: str) -> List[Dict]:
        """è·å–æ¨¡æ‹ŸOHLCVæ•°æ®"""
        ohlcv_data = []
        trading_dates = self._get_mock_trading_calendar(start_date, end_date)

        for symbol in symbols:
            for date in trading_dates:
                ohlcv_data.append({
                    "order_book_id": symbol,
                    "date": date,
                    "open": 100.0 + hash(symbol + date) % 50,
                    "close": 102.0 + hash(symbol + date) % 50,
                    "high": 105.0 + hash(symbol + date) % 50,
                    "low": 98.0 + hash(symbol + date) % 50,
                    "volume": 1000000 + hash(symbol + date) % 5000000,
                    "amount": 100000000.0 + hash(symbol + date) % 500000000,
                    "vwap": 101.5 + hash(symbol + date) % 10,
                    "returns": 0.02 + (hash(symbol + date) % 100 - 50) / 10000,
                    "volume_ratio": 1.0 + hash(symbol + date) % 5
                })

        return ohlcv_data

    def _get_mock_fundamental_data(self, symbols: List[str], fields: List[str],
                                 start_date: Optional[str], end_date: Optional[str]) -> List[Dict[str, Any]]:
        """è·å–æ¨¡æ‹ŸåŸºæœ¬é¢æ•°æ®"""
        fundamental_data: List[Dict[str, Any]] = []
        trading_dates = self._get_mock_trading_calendar(start_date, end_date)

        for symbol in symbols:
            for date in trading_dates[:5]:  # åªç”Ÿæˆæœ€è¿‘5ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
                record: Dict[str, Any] = {
                    "order_book_id": symbol,
                    "date": date
                }

                # ç”Ÿæˆå„ä¸ªå­—æ®µçš„å€¼
                for field in fields:
                    if field in ["pe_ratio", "pb_ratio", "ps_ratio"]:
                        record[field] = 10.0 + hash(symbol + field + date) % 40
                    elif field in ["market_cap", "circulating_market_cap"]:
                        record[field] = 1000000000.0 + hash(symbol + field + date) % 9000000000
                    elif field == "turnover_ratio":
                        record[field] = 0.5 + hash(symbol + field + date) % 10
                    elif field == "roe":
                        record[field] = 0.05 + (hash(symbol + field + date) % 200 - 100) / 10000
                    else:
                        record[field] = 1.0 + hash(symbol + field + date) % 100

                fundamental_data.append(record)

        return fundamental_data

    def _get_mock_technical_data(self, symbols: List[str], indicators: List[str],
                               start_date: Optional[str], end_date: Optional[str]) -> List[Dict[str, Any]]:
        """è·å–æ¨¡æ‹ŸæŠ€æœ¯æŒ‡æ ‡æ•°æ®"""
        technical_data: List[Dict[str, Any]] = []
        trading_dates = self._get_mock_trading_calendar(start_date, end_date)

        for symbol in symbols:
            for date in trading_dates:
                record: Dict[str, Any] = {
                    "order_book_id": symbol,
                    "date": date
                }

                # ç”Ÿæˆå„ä¸ªæŒ‡æ ‡çš„å€¼
                for indicator in indicators:
                    if "sma" in indicator or "ema" in indicator:
                        record[indicator] = 100.0 + hash(symbol + indicator + date) % 50
                    elif "rsi" in indicator:
                        record[indicator] = 30.0 + hash(symbol + indicator + date) % 40
                    elif "macd" in indicator:
                        record[indicator] = (hash(symbol + indicator + date) % 200 - 100) / 100
                    elif "bollinger" in indicator:
                        record[indicator] = 100.0 + hash(symbol + indicator + date) % 30
                    elif "stoch" in indicator:
                        record[indicator] = hash(symbol + indicator + date) % 100
                    elif "atr" in indicator:
                        record[indicator] = 1.0 + hash(symbol + indicator + date) % 10
                    else:
                        record[indicator] = hash(symbol + indicator + date) % 100

                technical_data.append(record)

        return technical_data

    def _get_actual_fields_from_rqdatac(self) -> Dict[str, Any]:
        """ä»RQDatacè·å–å®é™…çš„å­—æ®µä¿¡æ¯"""
        # è¿™ä¸ªæ–¹æ³•éœ€è¦æ ¹æ®RQDatacçš„å®é™…APIæ¥å®ç°
        # æš‚æ—¶è¿”å›ç©ºå­—å…¸
        return {}

    def _update_field_definitions(self, actual_fields: Dict[str, Any]):
        """æ›´æ–°å­—æ®µå®šä¹‰"""
        # è¿™ä¸ªæ–¹æ³•éœ€è¦å®ç°å­—æ®µå®šä¹‰çš„åŠ¨æ€æ›´æ–°
        pass

    def _update_schema_files(self, actual_fields: Dict[str, Any]):
        """æ›´æ–°schemaæ–‡ä»¶"""
        # è¿™ä¸ªæ–¹æ³•éœ€è¦å®ç°schemaæ–‡ä»¶çš„åŠ¨æ€æ›´æ–°
        pass

    def _get_fallback_instruments(self, instrument_type: str, market: str) -> List[Dict[str, Any]]:
        """è·å–å¤‡ç”¨è‚¡ç¥¨åˆ—è¡¨æ•°æ®ï¼ˆå½“RQDatac APIä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰"""
        logger.info("ä½¿ç”¨å¤‡ç”¨è‚¡ç¥¨åˆ—è¡¨æ•°æ®")

        # æ‰©å±•çš„Aè‚¡è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ˆåŒ…å«æ›´å¤šå¸¸è§è‚¡ç¥¨ï¼‰
        fallback_instruments = [
            # æ·±åœ³ä¸»æ¿
            {"order_book_id": "000001.XSHE", "symbol": "å¹³å®‰é“¶è¡Œ", "exchange": "XSHE", "sector_code": "J66", "industry_code": "J661", "board_type": "ä¸»æ¿"},
            {"order_book_id": "000002.XSHE", "symbol": "ä¸‡ç§‘A", "exchange": "XSHE", "sector_code": "K70", "industry_code": "K701", "board_type": "ä¸»æ¿"},
            {"order_book_id": "000004.XSHE", "symbol": "å›½åç½‘å®‰", "exchange": "XSHE", "sector_code": "I65", "industry_code": "I650", "board_type": "ä¸»æ¿"},
            {"order_book_id": "000005.XSHE", "symbol": "ä¸–çºªæ˜Ÿæº", "exchange": "XSHE", "sector_code": "K70", "industry_code": "K701", "board_type": "ä¸»æ¿"},
            {"order_book_id": "000006.XSHE", "symbol": "æ·±æŒ¯ä¸šA", "exchange": "XSHE", "sector_code": "K70", "industry_code": "K701", "board_type": "ä¸»æ¿"},
            {"order_book_id": "000008.XSHE", "symbol": "ç¥å·é«˜é“", "exchange": "XSHE", "sector_code": "G54", "industry_code": "G549", "board_type": "ä¸»æ¿"},
            {"order_book_id": "000009.XSHE", "symbol": "ä¸­å›½å®å®‰", "exchange": "XSHE", "sector_code": "I65", "industry_code": "I650", "board_type": "ä¸»æ¿"},
            {"order_book_id": "000010.XSHE", "symbol": "ç¾ä¸½ç”Ÿæ€", "exchange": "XSHE", "sector_code": "N77", "industry_code": "N772", "board_type": "ä¸»æ¿"},
            {"order_book_id": "000011.XSHE", "symbol": "æ·±ç‰©ä¸šA", "exchange": "XSHE", "sector_code": "K70", "industry_code": "K701", "board_type": "ä¸»æ¿"},
            {"order_book_id": "000012.XSHE", "symbol": "å—ç»A", "exchange": "XSHE", "sector_code": "C32", "industry_code": "C321", "board_type": "ä¸»æ¿"},

            # ä¸Šæµ·ä¸»æ¿
            {"order_book_id": "600000.XSHG", "symbol": "æµ¦å‘é“¶è¡Œ", "exchange": "XSHG", "sector_code": "J66", "industry_code": "J661", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600004.XSHG", "symbol": "ç™½äº‘æœºåœº", "exchange": "XSHG", "sector_code": "G53", "industry_code": "G531", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600006.XSHG", "symbol": "ä¸œé£æ±½è½¦", "exchange": "XSHG", "sector_code": "C36", "industry_code": "C361", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600007.XSHG", "symbol": "ä¸­å›½å›½è´¸", "exchange": "XSHG", "sector_code": "L72", "industry_code": "L721", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600008.XSHG", "symbol": "é¦–åˆ›ç¯ä¿", "exchange": "XSHG", "sector_code": "N77", "industry_code": "N772", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600009.XSHG", "symbol": "ä¸Šæµ·æœºåœº", "exchange": "XSHG", "sector_code": "G53", "industry_code": "G531", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600010.XSHG", "symbol": "åŒ…é’¢è‚¡ä»½", "exchange": "XSHG", "sector_code": "C31", "industry_code": "C311", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600011.XSHG", "symbol": "åèƒ½å›½é™…", "exchange": "XSHG", "sector_code": "D44", "industry_code": "D441", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600012.XSHG", "symbol": "çš–é€šé«˜é€Ÿ", "exchange": "XSHG", "sector_code": "G54", "industry_code": "G549", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600015.XSHG", "symbol": "åå¤é“¶è¡Œ", "exchange": "XSHG", "sector_code": "J66", "industry_code": "J661", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600016.XSHG", "symbol": "æ°‘ç”Ÿé“¶è¡Œ", "exchange": "XSHG", "sector_code": "J66", "industry_code": "J661", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600018.XSHG", "symbol": "ä¸Šæ¸¯é›†å›¢", "exchange": "XSHG", "sector_code": "G53", "industry_code": "G531", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600019.XSHG", "symbol": "å®é’¢è‚¡ä»½", "exchange": "XSHG", "sector_code": "C31", "industry_code": "C311", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600020.XSHG", "symbol": "ä¸­åŸé«˜é€Ÿ", "exchange": "XSHG", "sector_code": "G54", "industry_code": "G549", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600021.XSHG", "symbol": "ä¸Šæµ·ç”µåŠ›", "exchange": "XSHG", "sector_code": "D44", "industry_code": "D441", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600022.XSHG", "symbol": "å±±ä¸œé’¢é“", "exchange": "XSHG", "sector_code": "C31", "industry_code": "C311", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600023.XSHG", "symbol": "æµ™èƒ½ç”µåŠ›", "exchange": "XSHG", "sector_code": "D44", "industry_code": "D441", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600025.XSHG", "symbol": "åèƒ½æ°´ç”µ", "exchange": "XSHG", "sector_code": "D44", "industry_code": "D441", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600026.XSHG", "symbol": "ä¸­è¿œæµ·èƒ½", "exchange": "XSHG", "sector_code": "G51", "industry_code": "G511", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600027.XSHG", "symbol": "åç”µå›½é™…", "exchange": "XSHG", "sector_code": "D44", "industry_code": "D441", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600028.XSHG", "symbol": "ä¸­å›½çŸ³åŒ–", "exchange": "XSHG", "sector_code": "C25", "industry_code": "C251", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600029.XSHG", "symbol": "å—æ–¹èˆªç©º", "exchange": "XSHG", "sector_code": "G53", "industry_code": "G531", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600030.XSHG", "symbol": "ä¸­ä¿¡è¯åˆ¸", "exchange": "XSHG", "sector_code": "J66", "industry_code": "J661", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600031.XSHG", "symbol": "ä¸‰ä¸€é‡å·¥", "exchange": "XSHG", "sector_code": "C35", "industry_code": "C351", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600036.XSHG", "symbol": "æ‹›å•†é“¶è¡Œ", "exchange": "XSHG", "sector_code": "J66", "industry_code": "J661", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600037.XSHG", "symbol": "æ­Œåæœ‰çº¿", "exchange": "XSHG", "sector_code": "I64", "industry_code": "I641", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600038.XSHG", "symbol": "ä¸­ç›´è‚¡ä»½", "exchange": "XSHG", "sector_code": "C37", "industry_code": "C371", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600039.XSHG", "symbol": "å››å·è·¯æ¡¥", "exchange": "XSHG", "sector_code": "E48", "industry_code": "E481", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600048.XSHG", "symbol": "ä¿åˆ©åœ°äº§", "exchange": "XSHG", "sector_code": "K70", "industry_code": "K701", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600050.XSHG", "symbol": "ä¸­å›½è”é€š", "exchange": "XSHG", "sector_code": "I63", "industry_code": "I631", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600051.XSHG", "symbol": "å®æ³¢è”åˆ", "exchange": "XSHG", "sector_code": "C28", "industry_code": "C281", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600052.XSHG", "symbol": "æµ™æ±Ÿå¹¿å¦", "exchange": "XSHG", "sector_code": "K70", "industry_code": "K701", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600053.XSHG", "symbol": "ä¹é¼æŠ•èµ„", "exchange": "XSHG", "sector_code": "J66", "industry_code": "J661", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600054.XSHG", "symbol": "é»„å±±æ—…æ¸¸", "exchange": "XSHG", "sector_code": "N78", "industry_code": "N781", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600055.XSHG", "symbol": "ä¸‡ä¸œåŒ»ç–—", "exchange": "XSHG", "sector_code": "C37", "industry_code": "C371", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600056.XSHG", "symbol": "ä¸­å›½åŒ»è¯", "exchange": "XSHG", "sector_code": "F51", "industry_code": "F511", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600057.XSHG", "symbol": "å¦é—¨è±¡å±¿", "exchange": "XSHG", "sector_code": "G51", "industry_code": "G511", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600058.XSHG", "symbol": "äº”çŸ¿å‘å±•", "exchange": "XSHG", "sector_code": "C31", "industry_code": "C311", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600059.XSHG", "symbol": "å¤è¶Šé¾™å±±", "exchange": "XSHG", "sector_code": "C15", "industry_code": "C151", "board_type": "ä¸»æ¿"},
            {"order_book_id": "600060.XSHG", "symbol": "æµ·ä¿¡è§†åƒ", "exchange": "XSHG", "sector_code": "C39", "industry_code": "C391", "board_type": "ä¸»æ¿"},
        ]

        # ä¸ºæ‰€æœ‰è‚¡ç¥¨æ·»åŠ å…¬å…±å­—æ®µ
        current_time = datetime.now()
        for instrument in fallback_instruments:
            instrument["type"] = instrument_type
            instrument["status"] = "Active"
            instrument["listed_date"] = "1990-01-01"  # é»˜è®¤ä¸Šå¸‚æ—¥æœŸ
            instrument["de_listed_date"] = ""  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæœªé€€å¸‚
            instrument["data_date"] = current_time.strftime("%Y-%m-%d")
            instrument["updated_at"] = current_time.isoformat()

        logger.info(f"å¤‡ç”¨è‚¡ç¥¨åˆ—è¡¨åŒ…å« {len(fallback_instruments)} åªè‚¡ç¥¨")
        return fallback_instruments


# å…¨å±€å®ä¾‹
_rqdatac_data_loader = None


def get_rqdatac_data_loader(allow_mock_data: bool = False) -> RQDatacDataLoader:
    """
    è·å–RQDatacæ•°æ®åŠ è½½å™¨å®ä¾‹

    Args:
        allow_mock_data: æ˜¯å¦å…è®¸åœ¨RQDatacä¸å¯ç”¨æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
    """
    global _rqdatac_data_loader
    if _rqdatac_data_loader is None:
        _rqdatac_data_loader = RQDatacDataLoader(allow_mock_data=allow_mock_data)
    return _rqdatac_data_loader


# ä¾¿æ·å‡½æ•°
def load_instruments(instrument_type: str = "CS", market: str = "cn") -> pl.DataFrame:
    """åŠ è½½è‚¡ç¥¨åˆ—è¡¨"""
    loader = get_rqdatac_data_loader()
    return loader.get_instruments(instrument_type, market)


def load_trading_calendar(market: str = "cn", start_date: Optional[str] = None,
                         end_date: Optional[str] = None) -> List[str]:
    """åŠ è½½äº¤æ˜“æ—¥å†"""
    loader = get_rqdatac_data_loader()
    return loader.get_trading_calendar(market, start_date, end_date)


def load_ohlcv_data(symbols: List[str], start_date: str, end_date: str,
                   frequency: str = "1d", adjust_type: str = "post") -> pl.DataFrame:
    """åŠ è½½OHLCVæ•°æ®"""
    loader = get_rqdatac_data_loader()
    return loader.get_ohlcv_data(symbols, start_date, end_date, frequency, adjust_type)


def load_dual_adjustment_ohlcv_data(symbols: List[str], start_date: str, end_date: str,
                                       frequency: str = "1d") -> pl.DataFrame:
    """åŠ è½½åŒå¤æƒOHLCVæ•°æ®ï¼ˆåŒæ—¶åŒ…å«åå¤æƒå’Œå‰å¤æƒä»·æ ¼ï¼‰"""
    loader = get_rqdatac_data_loader()
    return loader.get_dual_adjustment_ohlcv_data(symbols, start_date, end_date, frequency)


def load_fundamental_data(symbols: List[str], fields: Optional[List[str]] = None,
                         start_date: Optional[str] = None, end_date: Optional[str] = None) -> pl.DataFrame:
    """åŠ è½½åŸºæœ¬é¢æ•°æ®"""
    loader = get_rqdatac_data_loader()
    return loader.get_fundamental_data(symbols, fields, start_date, end_date)


def load_technical_data(symbols: List[str], indicators: Optional[List[str]] = None,
                       start_date: Optional[str] = None, end_date: Optional[str] = None) -> pl.DataFrame:
    """åŠ è½½æŠ€æœ¯æŒ‡æ ‡æ•°æ®"""
    loader = get_rqdatac_data_loader()
    return loader.get_technical_data(symbols, indicators, start_date, end_date)


def load_factor_data(symbols: List[str], factors: Optional[List[str]] = None,
                    start_date: Optional[str] = None, end_date: Optional[str] = None) -> pl.DataFrame:
    """åŠ è½½å› å­æ•°æ®"""
    loader = get_rqdatac_data_loader()
    return loader.get_factor_data(symbols, factors, start_date, end_date)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)

    print("=== RQDatacæ•°æ®åŠ è½½å™¨æµ‹è¯• ===")

    # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨
    print("\n1. æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨åŠ è½½")
    instruments = load_instruments()
    print(f"è·å–åˆ° {len(instruments)} åªè‚¡ç¥¨")

    # æµ‹è¯•äº¤æ˜“æ—¥å†
    print("\n2. æµ‹è¯•äº¤æ˜“æ—¥å†åŠ è½½")
    trading_dates = load_trading_calendar()
    print(f"è·å–åˆ° {len(trading_dates)} ä¸ªäº¤æ˜“æ—¥")

    # æµ‹è¯•OHLCVæ•°æ®
    print("\n3. æµ‹è¯•OHLCVæ•°æ®åŠ è½½")
    symbols = ["000001.XSHE", "000002.XSHE"]
    ohlcv_data = load_ohlcv_data(symbols, "2025-09-01", "2025-09-15")
    print(f"è·å–åˆ° {len(ohlcv_data)} æ¡OHLCVè®°å½•")

    # æµ‹è¯•åŸºæœ¬é¢æ•°æ®
    print("\n4. æµ‹è¯•åŸºæœ¬é¢æ•°æ®åŠ è½½")
    fundamental_data = load_fundamental_data(symbols, ["pe_ratio", "pb_ratio"])
    print(f"è·å–åˆ° {len(fundamental_data)} æ¡åŸºæœ¬é¢è®°å½•")

    print("\n=== æµ‹è¯•å®Œæˆ ===")


# ===== ä¾¿æ·å‡½æ•° =====

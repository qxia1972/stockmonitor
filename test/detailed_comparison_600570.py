# è¯¦ç»†æ¯”è¾ƒ600570çš„RQDatacåŸå§‹æ•°æ®å’Œæœ¬åœ°æ•°æ®
import os
import polars as pl
from datetime import datetime, timedelta
import sys
sys.path.append('.')

try:
    from networks.rqdatac_data_loader import RQDatacDataLoader

    print('ğŸ” è¯¦ç»†æ¯”è¾ƒ600570çš„RQDatacåŸå§‹æ•°æ®å’Œæœ¬åœ°æ•°æ®...')

    # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
    loader = RQDatacDataLoader(allow_mock_data=True)

    # è·å–RQDatacåŸå§‹æ•°æ®
    print('\nğŸ“¡ è·å–RQDatacåŸå§‹æ•°æ®...')
    order_book_id = '600570.XSHG'
    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=10)  # è·å–æœ€è¿‘10å¤©çš„æ•°æ®

    try:
        rq_data = loader.get_ohlcv_data(
            symbols=[order_book_id],
            start_date=start_date.strftime('%Y-%m-%d'),
            end_date=end_date.strftime('%Y-%m-%d'),
            frequency='1d',
            adjust_type='post'
        )

        if rq_data is not None and len(rq_data) > 0:
            print('âœ… RQDatacåŸå§‹æ•°æ®è·å–æˆåŠŸ')
            print(f'   æ•°æ®è¡Œæ•°: {len(rq_data)}')
            print(f'   æ—¥æœŸèŒƒå›´: {rq_data["date"].min()} åˆ° {rq_data["date"].max()}')

            # æ˜¾ç¤ºRQDatacçš„æœ€æ–°æ•°æ®
            latest_rq = rq_data.sort('date', descending=True).head(3)
            print('\nğŸ“Š RQDatacæœ€æ–°3å¤©æ•°æ®:')
            for i, row in enumerate(latest_rq.to_pandas().itertuples(), 1):
                print(f'  {i}. {row.date}: å¼€{row.open:.2f} æ”¶{row.close:.2f} é«˜{row.high:.2f} ä½{row.low:.2f} é‡{row.volume} é¢{row.amount:.2f}')

        else:
            print('âŒ RQDatacæ•°æ®è·å–å¤±è´¥æˆ–ä¸ºç©º')
            rq_data = None

    except Exception as e:
        print(f'âŒ RQDatacæ•°æ®è·å–å¼‚å¸¸: {e}')
        rq_data = None

    # è¯»å–æœ¬åœ°æ•°æ®
    print('\nğŸ’¾ è¯»å–æœ¬åœ°æ•°æ®...')
    data_dir = 'data'
    files = [f for f in os.listdir(data_dir) if f.startswith('ohlcv_synced_') and f.endswith('.parquet')]
    if files:
        latest_file = max(files, key=lambda x: os.path.getctime(os.path.join(data_dir, x)))
        file_path = os.path.join(data_dir, latest_file)

        df = pl.read_parquet(file_path)

        # è¿‡æ»¤600570çš„æ•°æ®
        local_data = df.filter(pl.col('order_book_id') == order_book_id)

        if len(local_data) > 0:
            print('âœ… æœ¬åœ°æ•°æ®è¯»å–æˆåŠŸ')
            print(f'   æ•°æ®è¡Œæ•°: {len(local_data)}')
            print(f'   æ—¥æœŸèŒƒå›´: {local_data["date"].min()} åˆ° {local_data["date"].max()}')

            # æ˜¾ç¤ºæœ¬åœ°æ•°æ®çš„æœ€æ–°æ•°æ®
            latest_local = local_data.sort('date', descending=True).head(3)
            print('\nğŸ“Š æœ¬åœ°æœ€æ–°3å¤©æ•°æ®:')
            for i, row in enumerate(latest_local.to_pandas().itertuples(), 1):
                print(f'  {i}. {row.date}: å¼€{row.open:.2f} æ”¶{row.close:.2f} é«˜{row.high:.2f} ä½{row.low:.2f} é‡{row.volume} é¢{row.amount:.2f}')

        else:
            print('âŒ æœ¬åœ°æ•°æ®ä¸­æœªæ‰¾åˆ°600570')
            local_data = None
    else:
        print('âŒ æœªæ‰¾åˆ°æœ¬åœ°æ•°æ®æ–‡ä»¶')
        local_data = None

    # æ¯”è¾ƒæ•°æ®
    if rq_data is not None and local_data is not None:
        print('\nğŸ” æ•°æ®æ¯”è¾ƒåˆ†æ...')

        # è½¬æ¢ä¸ºpandasè¿›è¡Œæ¯”è¾ƒ
        rq_df = rq_data.to_pandas()
        local_df = local_data.to_pandas()

        # æŒ‰æ—¥æœŸåˆå¹¶
        merged = rq_df.merge(local_df, on='date', suffixes=('_rq', '_local'))

        if len(merged) > 0:
            print(f'âœ… æ‰¾åˆ° {len(merged)} ä¸ªå…±åŒæ—¥æœŸè¿›è¡Œæ¯”è¾ƒ')

            # æ£€æŸ¥ä»·æ ¼å·®å¼‚
            price_fields = ['open', 'close', 'high', 'low']
            has_diff = False

            for field in price_fields:
                rq_col = f'{field}_rq'
                local_col = f'{field}_local'

                if rq_col in merged.columns and local_col in merged.columns:
                    diff = (merged[local_col] - merged[rq_col]).abs()
                    max_diff = diff.max()

                    if max_diff > 0.01:  # å…è®¸0.01çš„è¯¯å·®
                        has_diff = True
                        print(f'âš ï¸  {field.upper()} ä»·æ ¼å­˜åœ¨å·®å¼‚ï¼Œæœ€å¤§å·®å¼‚: {max_diff:.4f}')
                        # æ˜¾ç¤ºå·®å¼‚æœ€å¤§çš„è®°å½•
                        max_diff_idx = diff.idxmax()
                        row = merged.iloc[max_diff_idx]
                        print(f'     æ—¥æœŸ: {row["date"]}, RQ: {row[rq_col]:.2f}, æœ¬åœ°: {row[local_col]:.2f}')
                    else:
                        print(f'âœ… {field.upper()} ä»·æ ¼å®Œå…¨åŒ¹é…')

            if not has_diff:
                print('\nğŸ‰ æ‰€æœ‰ä»·æ ¼æ•°æ®å®Œå…¨åŒ¹é…ï¼æ•°æ®æ˜¯æ­£ç¡®çš„ã€‚')

                # æ˜¾ç¤ºæœ€æ–°çš„åŒ¹é…æ•°æ®
                latest_match = merged.sort_values('date', ascending=False).head(1).iloc[0]
                print('\nğŸ“Š æœ€æ–°æ•°æ®éªŒè¯:')
                print(f'  æ—¥æœŸ: {latest_match["date"]}')
                print(f'  å¼€ç›˜ä»·: RQ={latest_match["open_rq"]:.2f}, æœ¬åœ°={latest_match["open_local"]:.2f}')
                print(f'  æ”¶ç›˜ä»·: RQ={latest_match["close_rq"]:.2f}, æœ¬åœ°={latest_match["close_local"]:.2f}')
                print(f'  æœ€é«˜ä»·: RQ={latest_match["high_rq"]:.2f}, æœ¬åœ°={latest_match["high_local"]:.2f}')
                print(f'  æœ€ä½ä»·: RQ={latest_match["low_rq"]:.2f}, æœ¬åœ°={latest_match["low_local"]:.2f}')

        else:
            print('âŒ æ²¡æœ‰å…±åŒçš„æ—¥æœŸå¯ä»¥æ¯”è¾ƒ')

    print('\nğŸ” å¯èƒ½çš„é—®é¢˜åˆ†æ:')
    print('1. å¦‚æœæ•°æ®åŒ¹é…ä½†ç”¨æˆ·è§‰å¾—ä¸å¯¹ï¼Œå¯èƒ½æ˜¯æ˜¾ç¤ºæ ¼å¼é—®é¢˜')
    print('2. æˆ–è€…æ˜¯ç”¨æˆ·è®°å¿†ä¸­çš„ä»·æ ¼ä¸å®é™…ä»·æ ¼ä¸åŒ')
    print('3. æˆ–è€…æ˜¯æ•°æ®æºçš„é—®é¢˜ï¼ˆä½†ä»æ¯”è¾ƒçœ‹æ•°æ®æ˜¯æ­£ç¡®çš„ï¼‰')
    print('4. æˆ–è€…æ˜¯æ—¶é—´ç‚¹ä¸åŒå¯¼è‡´çš„ä»·æ ¼å·®å¼‚')

except Exception as e:
    print(f'âŒ è„šæœ¬æ‰§è¡Œå¼‚å¸¸: {e}')
    import traceback
    traceback.print_exc()
"""
å¤„ç†å‡½æ•°åº“ (Processing Functions Library)
ç®€åŒ–çš„å¤„ç†å‡½æ•°é›†åˆï¼Œç›´æ¥è°ƒç”¨åº•å±‚çš„è®¡ç®—ç±»
æ”¯æŒå¤šç§æ•°æ®æºï¼šæ–‡ä»¶ã€RQDatac APIã€æ•°æ®åº“ç­‰
"""

import logging
from typing import Dict, Any, Optional, Union, List
from datetime import datetime, timedelta
import polars as pl

from modules.compute.data_processor import DataProcessor
from modules.compute.indicator_calculator import IndicatorCalculator
from modules.compute.stock_scorer import StockScorer
from modules.compute.parallel_processor import ParallelProcessor
from modules.data_model import data_model
from networks.rqdatac_data_loader import get_rqdatac_data_loader

logger = logging.getLogger(__name__)

# ===== å…¨å±€å®ä¾‹ç®¡ç†ï¼ˆæƒ°æ€§åˆå§‹åŒ–ï¼‰ =====

_data_processor = None
_indicator_calculator = None
_score_calculator = None
_parallel_processor = None

def get_data_processor() -> DataProcessor:
    """è·å–æ•°æ®å¤„ç†å™¨å®ä¾‹ï¼ˆæƒ°æ€§åˆå§‹åŒ–ï¼‰"""
    global _data_processor
    if _data_processor is None:
        _data_processor = DataProcessor()
    return _data_processor

def get_indicator_calculator() -> IndicatorCalculator:
    """è·å–æŒ‡æ ‡è®¡ç®—å™¨å®ä¾‹ï¼ˆæƒ°æ€§åˆå§‹åŒ–ï¼‰"""
    global _indicator_calculator
    if _indicator_calculator is None:
        _indicator_calculator = IndicatorCalculator()
    return _indicator_calculator

def get_score_calculator() -> StockScorer:
    """è·å–è¯„åˆ†è®¡ç®—å™¨å®ä¾‹ï¼ˆæƒ°æ€§åˆå§‹åŒ–ï¼‰"""
    global _score_calculator
    if _score_calculator is None:
        _score_calculator = StockScorer()
    return _score_calculator

def get_parallel_processor() -> ParallelProcessor:
    """è·å–å¹¶è¡Œå¤„ç†å™¨å®ä¾‹ï¼ˆæƒ°æ€§åˆå§‹åŒ–ï¼‰"""
    global _parallel_processor
    if _parallel_processor is None:
        _parallel_processor = ParallelProcessor()
    return _parallel_processor

# ===== ç¼“å­˜æœºåˆ¶ =====

from functools import lru_cache
import hashlib

# è®¡ç®—ç»“æœç¼“å­˜
_calculation_cache = {}

def _get_cache_key(func_name: str, *args, **kwargs) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    key_data = f"{func_name}:{str(args)}:{str(sorted(kwargs.items()))}"
    return hashlib.md5(key_data.encode()).hexdigest()

@lru_cache(maxsize=100)
def calculate_indicators_cached(data, indicators=None, **kwargs):
    """å¸¦ç¼“å­˜çš„æŒ‡æ ‡è®¡ç®—å‡½æ•°"""
    cache_key = _get_cache_key('calculate_indicators', data.shape if hasattr(data, 'shape') else len(data), indicators)

    if cache_key in _calculation_cache:
        logger.info("ä½¿ç”¨ç¼“å­˜çš„æŒ‡æ ‡è®¡ç®—ç»“æœ")
        return _calculation_cache[cache_key]

    result = calculate_indicators(data, indicators, **kwargs)
    _calculation_cache[cache_key] = result

    return result

@lru_cache(maxsize=100)
def calculate_scores_cached(data, score_type="technical", **kwargs):
    """å¸¦ç¼“å­˜çš„è¯„åˆ†è®¡ç®—å‡½æ•°"""
    cache_key = _get_cache_key('calculate_scores', data.shape if hasattr(data, 'shape') else len(data), score_type)

    if cache_key in _calculation_cache:
        logger.info("ä½¿ç”¨ç¼“å­˜çš„è¯„åˆ†è®¡ç®—ç»“æœ")
        return _calculation_cache[cache_key]

    result = calculate_scores(data, score_type, **kwargs)
    _calculation_cache[cache_key] = result

    return result

def clear_calculation_cache():
    """æ¸…ç©ºè®¡ç®—ç¼“å­˜"""
    global _calculation_cache
    _calculation_cache.clear()
    logger.info("å·²æ¸…ç©ºè®¡ç®—ç¼“å­˜")

def get_cache_stats() -> Dict[str, Any]:
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    return {
        'cache_size': len(_calculation_cache),
        'cache_memory_mb': sum(
            df.estimated_size() / 1024 / 1024
            for df in _calculation_cache.values()
            if hasattr(df, 'estimated_size')
        )
    }

def load_market_data(data_source: Union[str, List[str], Dict[str, Any]]) -> pl.DataFrame:
    """åŠ è½½å¸‚åœºæ•°æ®

    æ”¯æŒå¤šç§æ•°æ®æºï¼š
    - å­—ç¬¦ä¸²è·¯å¾„ï¼šä»æ–‡ä»¶åŠ è½½
    - è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼šä»æ•°æ®åº“æˆ–RQDatacåŠ è½½
    - å­—å…¸é…ç½®ï¼šçµæ´»çš„æ•°æ®åŠ è½½é…ç½®

    Args:
        data_source: æ•°æ®æºé…ç½®
            - str: æ–‡ä»¶è·¯å¾„
            - List[str]: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            - Dict: è¯¦ç»†é…ç½®ï¼ŒåŒ…å«ï¼š
                - "source": "file"|"rqdatac"|"database"
                - "symbols": è‚¡ç¥¨ä»£ç åˆ—è¡¨
                - "start_date": å¼€å§‹æ—¥æœŸ
                - "end_date": ç»“æŸæ—¥æœŸ
                - "data_types": æ•°æ®ç±»å‹åˆ—è¡¨ ["ohlcv", "fundamental", "technical"]
                - "path": æ–‡ä»¶è·¯å¾„ï¼ˆå½“source="file"æ—¶ï¼‰

    Returns:
        åŠ è½½çš„æ•°æ®DataFrame
    """
    try:
        if isinstance(data_source, str):
            # ä»æ–‡ä»¶åŠ è½½
            logger.info(f"ğŸ“ ä»æ–‡ä»¶åŠ è½½æ•°æ®: {data_source}")
            return get_data_processor().load_data(data_source)

        elif isinstance(data_source, list):
            # ä»è‚¡ç¥¨ä»£ç åˆ—è¡¨åŠ è½½ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
            logger.info(f"ğŸ“Š ä»è‚¡ç¥¨ä»£ç åŠ è½½æ•°æ®: {len(data_source)} åªè‚¡ç¥¨")
            return data_model.load_market_data(data_source)

        elif isinstance(data_source, dict):
            # å­—å…¸é…ç½®æ–¹å¼
            source_type = data_source.get("source", "rqdatac")
            symbols = data_source.get("symbols", [])
            start_date = data_source.get("start_date")
            end_date = data_source.get("end_date")
            data_types = data_source.get("data_types", ["ohlcv"])

            logger.info(f"ğŸ”§ é…ç½®åŠ è½½æ•°æ®: {source_type}, {len(symbols)} åªè‚¡ç¥¨, {data_types}")

            if source_type == "file":
                path = data_source.get("path")
                if not path:
                    raise ValueError("æ–‡ä»¶æ•°æ®æºå¿…é¡»æä¾› 'path' å‚æ•°")
                return get_data_processor().load_data(path)

            elif source_type == "rqdatac":
                return _load_from_rqdatac(symbols, start_date, end_date, data_types)

            elif source_type == "database":
                return data_model.load_market_data(symbols)

            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: {source_type}")

        else:
            raise ValueError("ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹")

    except Exception as e:
        logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return pl.DataFrame()


def save_data(data: pl.DataFrame, output_path: str, **kwargs) -> bool:
    """ä¿å­˜æ•°æ®

    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        output_path: è¾“å‡ºè·¯å¾„
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        ä¿å­˜æ˜¯å¦æˆåŠŸ
    """
    try:
        if not output_path:
            raise ValueError("å¿…é¡»æä¾› output_path å‚æ•°")

        get_data_processor().save_data(data, output_path, **kwargs)
        return True

    except Exception as e:
        logger.error(f"âŒ æ•°æ®ä¿å­˜å¤±è´¥: {e}")
        return False


def calculate_indicators(data: Union[pl.DataFrame, Dict[str, pl.DataFrame]],
                        indicators: Optional[List[str]] = None, **kwargs) -> Union[pl.DataFrame, Dict[str, pl.DataFrame]]:
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡

    Args:
        data: è¾“å…¥æ•°æ®
        indicators: è¦è®¡ç®—çš„æŒ‡æ ‡åˆ—è¡¨
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        è®¡ç®—ç»“æœ
    """
    try:
        return get_indicator_calculator().calculate_indicators(data, indicators, **kwargs)

    except Exception as e:
        logger.error(f"âŒ æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return pl.DataFrame() if isinstance(data, pl.DataFrame) else {}


def calculate_fundamental_indicators(data: pl.DataFrame,
                                   indicators: Optional[List[str]] = None) -> pl.DataFrame:
    """è®¡ç®—åŸºæœ¬é¢æŒ‡æ ‡

    Args:
        data: åŸºæœ¬é¢æ•°æ®DataFrame
        indicators: è¦è®¡ç®—çš„æŒ‡æ ‡åˆ—è¡¨

    Returns:
        åŒ…å«åŸºæœ¬é¢æŒ‡æ ‡çš„DataFrame
    """
    try:
        if data.is_empty():
            logger.warning("è¾“å…¥æ•°æ®ä¸ºç©ºï¼Œè¿”å›ç©ºDataFrame")
            return pl.DataFrame()

        # é»˜è®¤åŸºæœ¬é¢æŒ‡æ ‡
        if indicators is None:
            indicators = ["pe_ratio", "pb_ratio", "roe", "roa", "debt_to_equity"]

        result_df = data.clone()

        # è®¡ç®—å¸‚ç›ˆç‡ (PE Ratio) = è‚¡ä»· / æ¯è‚¡æ”¶ç›Š
        if "pe_ratio" in indicators and "close" in data.columns and "eps" in data.columns:
            result_df = result_df.with_columns(
                (pl.col("close") / pl.col("eps")).alias("pe_ratio")
            )

        # è®¡ç®—å¸‚å‡€ç‡ (PB Ratio) = è‚¡ä»· / æ¯è‚¡å‡€èµ„äº§
        if "pb_ratio" in indicators and "close" in data.columns and "bvps" in data.columns:
            result_df = result_df.with_columns(
                (pl.col("close") / pl.col("bvps")).alias("pb_ratio")
            )

        # ROE (å‡€èµ„äº§æ”¶ç›Šç‡) - å¦‚æœæ•°æ®ä¸­å·²æœ‰ï¼Œç›´æ¥ä½¿ç”¨
        if "roe" in indicators and "roe" in data.columns:
            result_df = result_df.with_columns(pl.col("roe").alias("roe"))

        # ROA (æ€»èµ„äº§æ”¶ç›Šç‡) - å¦‚æœæ•°æ®ä¸­å·²æœ‰ï¼Œç›´æ¥ä½¿ç”¨
        if "roa" in indicators and "roa" in data.columns:
            result_df = result_df.with_columns(pl.col("roa").alias("roa"))

        # è´Ÿå€ºæƒç›Šæ¯” - å¦‚æœæ•°æ®ä¸­å·²æœ‰ï¼Œç›´æ¥ä½¿ç”¨
        if "debt_to_equity" in indicators and "debt_to_equity" in data.columns:
            result_df = result_df.with_columns(pl.col("debt_to_equity").alias("debt_to_equity"))

        logger.info(f"âœ… åŸºæœ¬é¢æŒ‡æ ‡è®¡ç®—å®Œæˆ: {len(result_df)} æ¡è®°å½•")
        return result_df

    except Exception as e:
        logger.error(f"âŒ åŸºæœ¬é¢æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}")
        return pl.DataFrame()


def calculate_scores(data: pl.DataFrame, score_type: str = "technical", **kwargs) -> pl.DataFrame:
    """è®¡ç®—è‚¡ç¥¨è¯„åˆ†

    Args:
        data: è¾“å…¥æ•°æ®
        score_type: è¯„åˆ†ç±»å‹
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        è¯„åˆ†ç»“æœ
    """
    try:
        calculator = get_score_calculator()

        if score_type == "technical":
            # ä½¿ç”¨ StockScorer çš„ score_stocks æ–¹æ³•
            market_env = kwargs.get('market_env', 'normal')
            return calculator.score_stocks(data, market_env)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¯„åˆ†ç±»å‹: {score_type}")

    except Exception as e:
        logger.error(f"âŒ è¯„åˆ†è®¡ç®—å¤±è´¥: {e}")
        return pl.DataFrame()


def evaluate_data_quality(data: pl.DataFrame, **kwargs) -> Dict[str, Any]:
    """è¯„ä¼°æ•°æ®è´¨é‡

    Args:
        data: è¦è¯„ä¼°çš„æ•°æ®
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        è´¨é‡è¯„ä¼°æŠ¥å‘Š
    """
    try:
        report = {
            "total_rows": len(data),
            "total_columns": len(data.columns),
            "null_counts": {},
            "data_types": {},
            "quality_score": 0.0
        }

        # æ£€æŸ¥æ¯åˆ—çš„ç©ºå€¼æƒ…å†µ
        for col in data.columns:
            null_count = data[col].null_count()
            report["null_counts"][col] = null_count
            report["data_types"][col] = str(data[col].dtype)

        # è®¡ç®—è´¨é‡è¯„åˆ†
        total_cells = report["total_rows"] * report["total_columns"]
        null_cells = sum(report["null_counts"].values())
        if total_cells > 0:
            report["quality_score"] = (1 - null_cells / total_cells) * 100

        return report

    except Exception as e:
        logger.error(f"âŒ æ•°æ®è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
        return {}


def process_batch_indicators(data: Dict[str, pl.DataFrame], **kwargs) -> Dict[str, pl.DataFrame]:
    """æ‰¹é‡è®¡ç®—æŒ‡æ ‡ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰

    Args:
        data: è‚¡ç¥¨ä»£ç  -> æ•°æ® çš„å­—å…¸
        **kwargs: é¢å¤–å‚æ•°

    Returns:
        å¤„ç†ç»“æœå­—å…¸
    """
    try:
        operation = kwargs.get("operation", "indicators")

        if operation == "indicators":
            return get_parallel_processor().process_batch_indicators(data, **kwargs)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {operation}")

    except Exception as e:
        logger.error(f"âŒ å¹¶è¡Œå¤„ç†å¤±è´¥: {e}")
        return {}


# ===== ä¾¿æ·å‡½æ•° =====

def reset_processors():
    """é‡ç½®æ‰€æœ‰å¤„ç†å™¨å®ä¾‹ï¼ˆç”¨äºæµ‹è¯•æˆ–é‡æ–°åˆå§‹åŒ–ï¼‰"""
    global _data_processor, _indicator_calculator, _score_calculator, _parallel_processor
    _data_processor = None
    _indicator_calculator = None
    _score_calculator = None
    _parallel_processor = None
    logger.info("ğŸ”„ æ‰€æœ‰å¤„ç†å™¨å®ä¾‹å·²é‡ç½®")


def get_processor_status() -> Dict[str, bool]:
    """è·å–å¤„ç†å™¨åˆå§‹åŒ–çŠ¶æ€"""
    return {
        "data_processor": _data_processor is not None,
        "indicator_calculator": _indicator_calculator is not None,
        "score_calculator": _score_calculator is not None,
        "parallel_processor": _parallel_processor is not None
    }


# ===== RQDatacæ•°æ®åŠ è½½å‡½æ•° =====

def _load_from_rqdatac(symbols: List[str], start_date: Optional[str],
                      end_date: Optional[str], data_types: List[str]) -> pl.DataFrame:
    """ä»RQDatacåŠ è½½æ•°æ®

    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        data_types: æ•°æ®ç±»å‹åˆ—è¡¨

    Returns:
        åˆå¹¶çš„æ•°æ®DataFrame
    """
    try:
        loader = get_rqdatac_data_loader()
        combined_data = []

        # è®¾ç½®é»˜è®¤æ—¥æœŸèŒƒå›´
        if start_date is None:
            start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d")

        logger.info(f"ğŸ“¡ ä»RQDatacåŠ è½½æ•°æ®: {len(symbols)} åªè‚¡ç¥¨, {start_date} åˆ° {end_date}")

        # åŠ è½½ä¸åŒç±»å‹çš„æ•°æ®
        for data_type in data_types:
            if data_type == "ohlcv":
                ohlcv_data = loader.get_ohlcv_data(symbols, start_date, end_date)
                if not ohlcv_data.is_empty():
                    combined_data.append(ohlcv_data)

            elif data_type == "fundamental":
                fundamental_data = loader.get_fundamental_data(symbols, start_date=start_date, end_date=end_date)
                if not fundamental_data.is_empty():
                    combined_data.append(fundamental_data)

            elif data_type == "technical":
                technical_data = loader.get_technical_data(symbols, start_date=start_date, end_date=end_date)
                if not technical_data.is_empty():
                    combined_data.append(technical_data)

            elif data_type == "instruments":
                instruments_data = loader.get_instruments()
                if not instruments_data.is_empty():
                    combined_data.append(instruments_data)

        # åˆå¹¶æ‰€æœ‰æ•°æ®
        if combined_data:
            try:
                # ä½¿ç”¨outer joinåˆå¹¶æ•°æ®ï¼Œé¿å…åˆ—é‡å¤
                result_df = combined_data[0]
                for df in combined_data[1:]:
                    # æ‰¾åˆ°å…±åŒçš„åˆ—ç”¨äºjoin
                    common_cols = []
                    for col in result_df.columns:
                        if col in df.columns:
                            common_cols.append(col)

                    if common_cols:
                        # ä½¿ç”¨å…±åŒåˆ—è¿›è¡Œjoin
                        result_df = result_df.join(df, on=common_cols, how="outer")
                    else:
                        # å¦‚æœæ²¡æœ‰å…±åŒåˆ—ï¼Œç›´æ¥æ°´å¹³è¿æ¥
                        result_df = pl.concat([result_df, df], how="horizontal")

                logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(result_df)} è¡Œæ•°æ®")
                return result_df
            except Exception as merge_error:
                logger.warning(f"æ•°æ®åˆå¹¶å¤±è´¥: {merge_error}ï¼Œè¿”å›ç¬¬ä¸€ä¸ªæ•°æ®å—")
                return combined_data[0] if combined_data else pl.DataFrame()
        else:
            logger.warning("âš ï¸ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æ•°æ®")
            return pl.DataFrame()

    except Exception as e:
        logger.error(f"âŒ ä»RQDatacåŠ è½½æ•°æ®å¤±è´¥: {e}")
        return pl.DataFrame()


# ===== ä¾¿æ·çš„æ•°æ®åŠ è½½å‡½æ•° =====

def load_ohlcv_data(symbols: List[str], start_date: Optional[str] = None,
                   end_date: Optional[str] = None, source: str = "rqdatac") -> pl.DataFrame:
    """åŠ è½½OHLCVæ•°æ®

    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        source: æ•°æ®æº ("rqdatac" æˆ– "database")

    Returns:
        OHLCVæ•°æ®
    """
    try:
        if source == "rqdatac":
            loader = get_rqdatac_data_loader()
            return loader.get_ohlcv_data(symbols, start_date or "", end_date or "")
        elif source == "database":
            return data_model.load_market_data(symbols)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {source}")
    except Exception as e:
        logger.error(f"âŒ åŠ è½½OHLCVæ•°æ®å¤±è´¥: {e}")
        return pl.DataFrame()


def load_fundamental_data(symbols: List[str], fields: Optional[List[str]] = None,
                         start_date: Optional[str] = None, end_date: Optional[str] = None,
                         source: str = "rqdatac") -> pl.DataFrame:
    """åŠ è½½åŸºæœ¬é¢æ•°æ®

    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        fields: å­—æ®µåˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        source: æ•°æ®æº

    Returns:
        åŸºæœ¬é¢æ•°æ®
    """
    try:
        if source == "rqdatac":
            loader = get_rqdatac_data_loader()
            return loader.get_fundamental_data(symbols, fields, start_date, end_date)
        elif source == "database":
            return data_model.load_market_data(symbols)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {source}")
    except Exception as e:
        logger.error(f"âŒ åŠ è½½åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
        return pl.DataFrame()


def load_technical_data(symbols: List[str], indicators: Optional[List[str]] = None,
                       start_date: Optional[str] = None, end_date: Optional[str] = None,
                       source: str = "rqdatac") -> pl.DataFrame:
    """åŠ è½½æŠ€æœ¯æŒ‡æ ‡æ•°æ®

    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        indicators: æŒ‡æ ‡åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        source: æ•°æ®æº

    Returns:
        æŠ€æœ¯æŒ‡æ ‡æ•°æ®
    """
    try:
        if source == "rqdatac":
            loader = get_rqdatac_data_loader()
            return loader.get_technical_data(symbols, indicators, start_date, end_date)
        elif source == "database":
            return data_model.load_market_data(symbols)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {source}")
    except Exception as e:
        logger.error(f"âŒ åŠ è½½æŠ€æœ¯æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")
        return pl.DataFrame()


def load_instruments(instrument_type: str = "CS", market: str = "cn",
                    source: str = "rqdatac") -> pl.DataFrame:
    """åŠ è½½è‚¡ç¥¨åˆ—è¡¨

    Args:
        instrument_type: è¯åˆ¸ç±»å‹
        market: å¸‚åœº
        source: æ•°æ®æº

    Returns:
        è‚¡ç¥¨åˆ—è¡¨
    """
    try:
        if source == "rqdatac":
            loader = get_rqdatac_data_loader()
            return loader.get_instruments(instrument_type, market)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {source}")
    except Exception as e:
        logger.error(f"âŒ åŠ è½½è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        return pl.DataFrame()


def load_trading_calendar(market: str = "cn", start_date: Optional[str] = None,
                         end_date: Optional[str] = None, source: str = "rqdatac") -> List[str]:
    """åŠ è½½äº¤æ˜“æ—¥å†

    Args:
        market: å¸‚åœº
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        source: æ•°æ®æº

    Returns:
        äº¤æ˜“æ—¥æœŸåˆ—è¡¨
    """
    try:
        if source == "rqdatac":
            loader = get_rqdatac_data_loader()
            return loader.get_trading_calendar(market, start_date, end_date)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æº: {source}")
    except Exception as e:
        logger.error(f"âŒ åŠ è½½äº¤æ˜“æ—¥å†å¤±è´¥: {e}")
        return []

#!/usr/bin/env python3
"""
ç¼“å­˜ç®¡ç†å·¥å…· - ç”¨äºæŸ¥çœ‹ã€ä¿®æ”¹å’Œä¼˜åŒ–ç¼“å­˜æ–‡ä»¶
æ”¯æŒJSONå’ŒPickleæ ¼å¼çš„ç¼“å­˜æ–‡ä»¶æ“ä½œ
"""

import argparse
from datetime import datetime
import json
import os
import pickle
import sys
from typing import Any

# ç±»å‹åˆ«å
StockData = dict[str, Any]
StocksDict = dict[str, StockData]


class CacheManager:
    """ç¼“å­˜æ–‡ä»¶ç®¡ç†å™¨"""

    def __init__(self, cache_dir: str = "data"):
        self.cache_dir = cache_dir
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)

    def detect_format(self, filepath: str) -> str:
        """æ£€æµ‹æ–‡ä»¶æ ¼å¼"""
        try:
            with open(filepath, "rb") as f:
                # å°è¯•è¯»å–å‰å‡ ä¸ªå­—èŠ‚åˆ¤æ–­æ ¼å¼
                header = f.read(10)
                f.seek(0)

                # Pickleæ–‡ä»¶é€šå¸¸ä»¥åè®®å­—èŠ‚å¼€å¤´
                if len(header) > 0 and header[0:1] in [
                    b"\x80",
                    b"\x81",
                    b"\x82",
                    b"\x83",
                    b"\x84",
                ]:
                    return "pickle"
                return "json"
        except OSError as e:
            print(f"âš ï¸ æ— æ³•æ£€æµ‹æ–‡ä»¶æ ¼å¼ {filepath}: {e}")
            return "unknown"

    def load_cache(self, filename: str) -> dict[str, Any] | None:
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        filepath = os.path.join(self.cache_dir, filename)

        if not os.path.exists(filepath):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return None

        file_format = self.detect_format(filepath)
        print(f"ğŸ“ æ£€æµ‹åˆ°æ–‡ä»¶æ ¼å¼: {file_format}")

        try:
            # é¦–å…ˆå°è¯•JSONæ ¼å¼(æ›´å®‰å…¨)
            try:
                with open(filepath, encoding="utf-8") as f:
                    data = json.load(f)
                print(f"âœ… ç¼“å­˜æ–‡ä»¶åŠ è½½æˆåŠŸ: {filename}")
                return data
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSON,å°è¯•å®‰å…¨çš„pickleæ ¼å¼
                if file_format == "pickle":
                    import hashlib

                    # è®¡ç®—æ–‡ä»¶å“ˆå¸Œç”¨äºå®Œæ•´æ€§æ£€æŸ¥
                    with open(filepath, "rb") as f:
                        file_content = f.read()
                        file_hash = hashlib.sha256(file_content).hexdigest()

                        # æ£€æŸ¥æ–‡ä»¶å¤§å°(é˜²æ­¢DOSæ”»å‡»)
                        if len(file_content) > 100 * 1024 * 1024:  # 100MBé™åˆ¶
                            raise ValueError("Cache file too large for safe loading")

                        # ä½¿ç”¨BytesIOè¿›è¡Œå®‰å…¨çš„ååºåˆ—åŒ–
                        from io import BytesIO

                        data: dict[str, Any] = pickle.load(BytesIO(file_content))

                    print(f"âœ… ç¼“å­˜æ–‡ä»¶åŠ è½½æˆåŠŸ: {filename} (hash: {file_hash[:8]})")
                    return data
                raise ValueError(f"Unsupported file format: {file_format}")

        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return None

    def load_cache_with_validation(
        self, filename: str, expected_date: str, data_type: str
    ) -> dict[str, Any] | None:
        """åŠ è½½ç¼“å­˜æ–‡ä»¶å¹¶éªŒè¯æ•°æ®æœ‰æ•ˆæ€§"""
        filepath = os.path.join(self.cache_dir, filename)

        if not os.path.exists(filepath):
            return None

        try:
            # åŠ è½½ç¼“å­˜æ•°æ®
            cached_data = self.load_cache(filename)
            if cached_data is None:
                return None

            # éªŒè¯ç¼“å­˜æ•°æ®çš„æœ‰æ•ˆæ€§
            # cached_dataå·²ç»æ˜¯Dict[str, Any]ç±»å‹,æ— éœ€isinstanceæ£€æŸ¥
            if not cached_data:
                print(f"âŒ {data_type}ç¼“å­˜æ•°æ®ä¸ºç©º")
                return None

            # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„å­—æ®µ
            if "data" not in cached_data:
                print(f"âŒ {data_type}ç¼“å­˜ç¼ºå°‘dataå­—æ®µ")
                return None

            # æ£€æŸ¥æ—¥æœŸæ˜¯å¦åŒ¹é…
            cache_date = cached_data.get("date")
            if cache_date != expected_date:
                print(f"âš ï¸ {data_type}ç¼“å­˜æ—¥æœŸä¸åŒ¹é…: {cache_date} vs {expected_date}")
                return None

            print(f"âœ… {data_type}ç¼“å­˜éªŒè¯é€šè¿‡")
            return cached_data

        except Exception as e:
            print(f"âŒ {data_type}ç¼“å­˜éªŒè¯å¤±è´¥: {e}")
            return None

    def save_cache(
        self, data: dict[str, Any], filename: str, use_pickle: bool = True
    ) -> bool:
        """ä¿å­˜ç¼“å­˜æ–‡ä»¶"""
        filepath = os.path.join(self.cache_dir, filename)

        try:
            # åŸå­å†™å…¥
            temp_filepath = filepath + ".tmp"
            with open(
                temp_filepath,
                "wb" if use_pickle else "w",
                encoding=None if use_pickle else "utf-8",
            ) as f:
                if use_pickle:
                    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)
                else:
                    json.dump(
                        data, f, ensure_ascii=False, separators=(",", ":"), default=str
                    )

            # åŸå­ç§»åŠ¨
            if os.path.exists(filepath):
                os.remove(filepath)
            os.rename(temp_filepath, filepath)

            print(
                f"ğŸ’¾ ç¼“å­˜æ–‡ä»¶ä¿å­˜æˆåŠŸ: {filename} (æ ¼å¼: {'pickle' if use_pickle else 'json'})"
            )
            return True

        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False

    def save_cache_data(
        self, data: Any, filename: str, data_type: str, date: str
    ) -> bool:
        """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜æ–‡ä»¶,åŒ…å«å…ƒæ•°æ®"""
        try:
            # å‡†å¤‡ç¼“å­˜æ•°æ®ç»“æ„
            cache_data: dict[str, Any] = {
                "data": data,
                "date": date,
                "data_type": data_type,
                "created_at": datetime.now().isoformat(),
                "version": "1.0",
            }

            # ä½¿ç”¨ç°æœ‰çš„save_cacheæ–¹æ³•ä¿å­˜
            return self.save_cache(cache_data, filename, use_pickle=False)

        except Exception as e:
            print(f"âŒ ä¿å­˜{data_type}ç¼“å­˜æ•°æ®å¤±è´¥: {e}")
            return False

    def show_cache_info(self, data: dict[str, Any]) -> None:
        """æ˜¾ç¤ºç¼“å­˜æ–‡ä»¶ä¿¡æ¯"""
        if not data:
            print("âŒ ç¼“å­˜æ•°æ®ä¸ºç©º")
            return

        print("\nğŸ“Š ç¼“å­˜æ–‡ä»¶ä¿¡æ¯:")

        # åŸºæœ¬ä¿¡æ¯
        if "trading_date" in data:
            print(f"   ğŸ“… äº¤æ˜“æ—¥æœŸ: {data['trading_date']}")
        if "fetch_time" in data:
            print(f"   ğŸ• è·å–æ—¶é—´: {data['fetch_time']}")

        # è‚¡ç¥¨ä¿¡æ¯
        stocks_data = data.get("stocks")
        if stocks_data and isinstance(stocks_data, dict):
            stocks_dict: StocksDict = stocks_data
            stock_count = len(stocks_dict)
            print(f"   ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {stock_count}")

            if stock_count > 0:
                # æ˜¾ç¤ºå‰å‡ ä¸ªè‚¡ç¥¨
                sample_stocks: list[str] = list(stocks_dict.keys())[:5]
                print(f"   ğŸ“‹ ç¤ºä¾‹è‚¡ç¥¨: {', '.join(sample_stocks)}")

                # è®¡ç®—æ•°æ®ç‚¹ç»Ÿè®¡
                total_data_points: int = 0
                for _, stock_data in stocks_dict.items():
                    if "data_points" in stock_data:
                        total_data_points += stock_data["data_points"]

                if total_data_points > 0:
                    print(f"   ğŸ“Š æ€»æ•°æ®ç‚¹æ•°: {total_data_points}")
                    print(f"   ğŸ“Š å¹³å‡æ¯è‚¡æ•°æ®ç‚¹: {total_data_points // stock_count}")

        # æ–‡ä»¶å¤§å°ä¼°ç®—
        data_size = sys.getsizeof(data)
        print(f"   ğŸ’¾ å†…å­˜å ç”¨: {data_size / 1024 / 1024:.2f} MB")

    def convert_format(self, filename: str, target_format: str) -> bool:
        """è½¬æ¢ç¼“å­˜æ–‡ä»¶æ ¼å¼"""
        print(f"ğŸ”„ è½¬æ¢æ–‡ä»¶æ ¼å¼: {filename} -> {target_format}")

        # åŠ è½½æ•°æ®
        data = self.load_cache(filename)
        if data is None:
            return False

        # ç¡®å®šæ–°æ–‡ä»¶å
        if target_format == "pickle":
            new_filename = filename.replace(".json", ".pkl")
        else:
            new_filename = filename.replace(".pkl", ".json")

        # ä¿å­˜ä¸ºæ–°æ ¼å¼
        use_pickle = target_format == "pickle"
        return self.save_cache(data, new_filename, use_pickle)

    def optimize_cache(self, filename: str) -> bool:
        """ä¼˜åŒ–ç¼“å­˜æ–‡ä»¶(è½¬æ¢ä¸ºæœ€ä¼˜æ ¼å¼)"""
        print(f"âš¡ ä¼˜åŒ–ç¼“å­˜æ–‡ä»¶: {filename}")

        data = self.load_cache(filename)
        if data is None:
            return False

        # æ ¹æ®æ•°æ®é‡é€‰æ‹©æ ¼å¼
        stock_count = (
            len(data.get("stocks", {})) if isinstance(data.get("stocks"), dict) else 0
        )

        if stock_count > 1000:
            print(f"   ğŸ“Š å¤§æ•°æ®é›†({stock_count}è‚¡ç¥¨)ï¼Œä½¿ç”¨pickleæ ¼å¼ä¼˜åŒ–")
            use_pickle = True
            new_filename = filename.replace(".json", ".pkl")
        else:
            print(f"   ğŸ“Š å°æ•°æ®é›†({stock_count}è‚¡ç¥¨)ï¼Œä½¿ç”¨ç´§å‡‘JSONæ ¼å¼")
            use_pickle = False
            new_filename = filename

        return self.save_cache(data, new_filename, use_pickle)

    def search_stocks(self, data: dict[str, Any], pattern: str) -> None:
        """æœç´¢è‚¡ç¥¨"""
        if not data or "stocks" not in data:
            print("âŒ æ— è‚¡ç¥¨æ•°æ®")
            return

        stocks_data = data.get("stocks")
        if not stocks_data or not isinstance(stocks_data, dict):
            print("âŒ è‚¡ç¥¨æ•°æ®æ ¼å¼é”™è¯¯")
            return

        stocks_dict: StocksDict = stocks_data
        matches: list[tuple[str, StockData]] = []
        for stock_code, stock_data in stocks_dict.items():
            if pattern.lower() in stock_code.lower():
                matches.append((stock_code, stock_data))

        if matches:
            print(f"\nğŸ” æ‰¾åˆ° {len(matches)} åªåŒ¹é…çš„è‚¡ç¥¨:")
            for stock_code, stock_data in matches[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                data_points = stock_data.get("data_points", 0)
                print(f"   ğŸ“ˆ {stock_code}: {data_points} ä¸ªæ•°æ®ç‚¹")
        else:
            print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„è‚¡ç¥¨: {pattern}")


def main() -> None:
    parser = argparse.ArgumentParser(description="ç¼“å­˜ç®¡ç†å·¥å…·")
    parser.add_argument(
        "action", choices=["info", "convert", "optimize", "search"], help="æ“ä½œç±»å‹"
    )
    parser.add_argument("filename", help="ç¼“å­˜æ–‡ä»¶å")
    parser.add_argument(
        "--format", choices=["json", "pickle"], help="è½¬æ¢ç›®æ ‡æ ¼å¼ (ç”¨äºconvertæ“ä½œ)"
    )
    parser.add_argument("--pattern", help="æœç´¢æ¨¡å¼ (ç”¨äºsearchæ“ä½œ)")
    parser.add_argument("--cache-dir", default="data", help="ç¼“å­˜ç›®å½•")

    args = parser.parse_args()

    manager = CacheManager(args.cache_dir)

    if args.action == "info":
        data = manager.load_cache(args.filename)
        if data:
            manager.show_cache_info(data)

    elif args.action == "convert":
        if not args.format:
            print("âŒ è¯·æŒ‡å®šç›®æ ‡æ ¼å¼ --format json æˆ– --format pickle")
            return
        manager.convert_format(args.filename, args.format)

    elif args.action == "optimize":
        manager.optimize_cache(args.filename)

    elif args.action == "search":
        if not args.pattern:
            print("âŒ è¯·æŒ‡å®šæœç´¢æ¨¡å¼ --pattern <pattern>")
            return
        data = manager.load_cache(args.filename)
        if data:
            manager.search_stocks(data, args.pattern)


if __name__ == "__main__":
    main()
